"""Vulnerability scanning tasks using the unified service layer."""

import logging
import os
from datetime import timedelta
from typing import Any, Dict

import dramatiq
from django.db import transaction
from tenacity import (
    before_sleep_log,
    retry,
    retry_if_exception_type,
    stop_after_delay,
    wait_exponential,
)

# Set up Django
os.environ.setdefault("DJANGO_SETTINGS_MODULE", "sbomify.settings")
import django  # noqa: E402

django.setup()

from django.db import connection  # noqa: E402
from django.db.utils import DatabaseError, OperationalError  # noqa: E402
from django.utils import timezone  # noqa: E402

# Import to ensure broker is configured with Results middleware
import sbomify.tasks  # noqa: F401, E402
from sbomify.apps.core.models import Release  # noqa: E402
from sbomify.apps.sboms.models import SBOM  # noqa: E402
from sbomify.apps.sboms.utils import SBOMDataError, get_sbom_data_bytes  # noqa: E402
from sbomify.task_utils import format_task_error, sbom_processing_task  # noqa: E402

from .clients import VulnerabilityProviderError  # noqa: E402
from .models import VulnerabilityScanResult  # noqa: E402
from .services import VulnerabilityScanningService  # noqa: E402

logger = logging.getLogger(__name__)

# Import cron decorator for scheduling (requires dramatiq-crontab)
# pip install dramatiq-crontab
try:
    from dramatiq_crontab import cron

    logger.info("dramatiq-crontab available - cron scheduling enabled")
except ImportError:
    logger.warning("dramatiq-crontab not installed - cron scheduling disabled, tasks will need manual triggering")

    # Fallback for environments without dramatiq-crontab
    def cron(schedule):
        """Fallback decorator when dramatiq-crontab is not installed."""

        def decorator(func):
            return func

        return decorator


def calculate_scan_timeout(sbom_data_bytes: bytes) -> int:
    """
    Calculate dynamic timeout based on SBOM size.

    Args:
        sbom_data_bytes: SBOM content as bytes

    Returns:
        Timeout in milliseconds
    """
    # Base timeout: 5 minutes
    base_timeout_ms = 300000

    # Additional time based on size
    size_mb = len(sbom_data_bytes) / (1024 * 1024)

    if size_mb < 1:
        return base_timeout_ms  # 5 minutes for small SBOMs
    elif size_mb < 10:
        return base_timeout_ms * 2  # 10 minutes for medium SBOMs
    elif size_mb < 50:
        return base_timeout_ms * 3  # 15 minutes for large SBOMs
    else:
        return base_timeout_ms * 4  # 20 minutes for very large SBOMs


@sbom_processing_task(queue_name="sbom_processing", time_limit=1200000)  # Default 20 minutes
def scan_sbom_for_vulnerabilities_unified(sbom_id: str) -> Dict[str, Any]:
    """
    Unified vulnerability scanning task that routes to OSV or Dependency Track based on team settings.

    This replaces the original OSV-only scanning task with a provider-agnostic approach.
    Features enhanced error handling and dynamic timeouts.
    """
    logger.info(f"[TASK_scan_sbom_for_vulnerabilities_unified] Starting vulnerability scan for SBOM ID: {sbom_id}")

    # Track task execution metadata
    start_time = timezone.now()
    task_metadata = {
        "sbom_id": sbom_id,
        "start_time": start_time,  # Will be converted to ISO format before return
        "provider": None,
        "sbom_size_mb": 0,
        "error_type": None,
    }

    try:
        # 1. Fetch SBOM data with timeout handling
        try:
            sbom_instance, sbom_data_bytes = get_sbom_data_bytes(sbom_id)
            task_metadata["sbom_size_mb"] = len(sbom_data_bytes) / (1024 * 1024)

            logger.info(
                f"[TASK_scan_sbom_for_vulnerabilities_unified] SBOM ID: {sbom_id} fetched. "
                f"Size: {task_metadata['sbom_size_mb']:.2f}MB, "
                f"Filename: {sbom_instance.sbom_filename}, Team: {sbom_instance.component.team.key}"
            )
        except Exception as e:
            task_metadata["error_type"] = "sbom_fetch_error"
            logger.error(f"Failed to fetch SBOM data for {sbom_id}: {str(e)}")
            raise SBOMDataError(f"Failed to fetch SBOM data: {str(e)}")

        # 2. Determine optimal timeout based on SBOM size
        calculated_timeout = calculate_scan_timeout(sbom_data_bytes)
        logger.info(
            f"Using dynamic timeout: {calculated_timeout / 1000:.1f} seconds "
            f"for SBOM size {task_metadata['sbom_size_mb']:.2f}MB"
        )

        # 3. Perform vulnerability scan with enhanced error handling
        try:
            service = VulnerabilityScanningService()
            results = service.scan_sbom_for_vulnerabilities(sbom_instance, sbom_data_bytes, scan_trigger="upload")

            task_metadata["provider"] = results.get("provider", "unknown")
            end_time = timezone.now()
            task_metadata["end_time"] = end_time.isoformat()
            task_metadata["duration_seconds"] = (end_time - start_time).total_seconds()
            # Convert start_time to ISO format for JSON serialization
            task_metadata["start_time"] = start_time.isoformat()

            logger.info(
                f"[TASK_scan_sbom_for_vulnerabilities_unified] Completed vulnerability scan for SBOM ID: {sbom_id}. "
                f"Provider: {task_metadata['provider']}, Duration: {task_metadata['duration_seconds']:.1f}s, "
                f"Results: {results.get('summary', 'No summary available')}"
            )

            return {
                **results,
                "task_metadata": task_metadata,
            }

        except VulnerabilityProviderError as e:
            task_metadata["error_type"] = "provider_error"
            logger.error(f"Vulnerability provider error for SBOM {sbom_id}: {str(e)}")
            return format_task_error("scan_sbom_for_vulnerabilities_unified", sbom_id, f"Provider error: {str(e)}")

        except TimeoutError as e:
            task_metadata["error_type"] = "timeout_error"
            logger.error(f"Vulnerability scan timeout for SBOM {sbom_id}: {str(e)}")
            return format_task_error(
                "scan_sbom_for_vulnerabilities_unified",
                sbom_id,
                f"Scan timeout after {calculated_timeout / 1000:.1f}s: {str(e)}",
            )

        except Exception as e:
            task_metadata["error_type"] = "unexpected_error"
            logger.error(f"Unexpected error during vulnerability scan for SBOM {sbom_id}: {str(e)}", exc_info=True)
            return format_task_error("scan_sbom_for_vulnerabilities_unified", sbom_id, f"Unexpected error: {str(e)}")

    except SBOMDataError as e:
        task_metadata["error_type"] = "sbom_data_error"
        return format_task_error("scan_sbom_for_vulnerabilities_unified", sbom_id, str(e))

    except Exception as e:
        task_metadata["error_type"] = "critical_error"
        logger.critical(f"Critical error in vulnerability scan task for SBOM {sbom_id}: {str(e)}", exc_info=True)
        return format_task_error("scan_sbom_for_vulnerabilities_unified", sbom_id, f"Critical error: {str(e)}")

    finally:
        # Log task completion metadata
        end_time = timezone.now()
        total_duration = (end_time - start_time).total_seconds()
        logger.info(
            f"[TASK_scan_sbom_for_vulnerabilities_unified] Task finished for SBOM {sbom_id}. "
            f"Total duration: {total_duration:.1f}s, Error type: {task_metadata.get('error_type', 'none')}"
        )


@cron("0 2 * * Sun")  # Run weekly on Sundays at 2 AM
@dramatiq.actor(queue_name="weekly_vulnerability_scan", max_retries=3, time_limit=7200000, store_results=True)
@retry(
    retry=retry_if_exception_type((OperationalError, DatabaseError)),
    wait=wait_exponential(multiplier=1, min=2, max=30),
    stop=stop_after_delay(300),
    before_sleep=before_sleep_log(logger, logging.WARNING),
)
def weekly_vulnerability_scan_task(
    days_back: int = 7, team_key: str = None, force_rescan: bool = False, max_releases: int = None
) -> Dict[str, Any]:
    """
    Comprehensive weekly vulnerability scanning task - automatically scheduled every Sunday at 2 AM.

    This task ensures complete vulnerability coverage by scanning:
    1. All SBOMs in recent releases (for release-based reporting)
    2. Latest SBOM for each component (for component-based reporting)

    This ensures both dashboard views (product/release focused) and component
    views (latest SBOM focused) have current vulnerability data.

    Args:
        days_back: Only scan releases created in the last N days (default: 7)
        team_key: Only scan components/releases for a specific team (for testing)
        force_rescan: Force rescan even if recent scans exist
        max_releases: Maximum number of releases to scan (for testing)

    Returns:
        Dictionary with scan statistics and results
    """
    logger.info(f"[TASK_weekly_vulnerability_scan] Starting weekly vulnerability scan at {timezone.now()}")

    try:
        # Get comprehensive scan targets (releases + latest component SBOMs)
        scan_targets = _get_comprehensive_scan_targets(days_back, team_key, max_releases)

        if not scan_targets["sboms"]:
            logger.info("[TASK_weekly_vulnerability_scan] No SBOMs found for scanning")
            return {
                "status": "completed",
                "total_releases": scan_targets["total_releases"],
                "total_components": scan_targets["total_components"],
                "total_sboms": 0,
                "successful_scans": 0,
                "failed_scans": 0,
                "skipped_scans": 0,
                "message": "No SBOMs found for scanning",
            }

        # Perform scans
        scan_results = _perform_comprehensive_scans(scan_targets, force_rescan)

        logger.info(
            f"[TASK_weekly_vulnerability_scan] Comprehensive vulnerability scan completed. "
            f"Processed {scan_results['total_releases']} releases, "
            f"{scan_results['total_components']} components, "
            f"{scan_results['successful_scans']} successful scans"
        )

        return {"status": "completed", **scan_results, "completed_at": timezone.now().isoformat()}

    except Exception:
        logger.exception("[TASK_weekly_vulnerability_scan] Weekly vulnerability scan failed")
        return {"status": "failed", "error": "Task failed", "failed_at": timezone.now().isoformat()}


def _get_comprehensive_scan_targets(days_back: int, team_key: str = None, max_releases: int = None) -> Dict[str, Any]:
    """Get comprehensive list of SBOMs to scan from both releases and latest component SBOMs."""
    from sbomify.apps.core.models import Component

    # Track all SBOMs to scan (deduplicated)
    sboms_to_scan = {}  # sbom_id -> (sbom, source_type, source_info)

    # 1. Get SBOMs from recent releases
    release_queryset = Release.objects.select_related("product__team").prefetch_related("artifacts__sbom")

    # Filter by team if specified
    if team_key:
        release_queryset = release_queryset.filter(product__team__key=team_key)

    # Filter by creation date
    if days_back:
        cutoff_date = timezone.now() - timedelta(days=days_back)
        release_queryset = release_queryset.filter(created_at__gte=cutoff_date)

    # Only get releases that have SBOMs
    release_queryset = release_queryset.filter(artifacts__sbom__isnull=False).distinct()

    # Apply max limit if specified
    if max_releases:
        release_queryset = release_queryset[:max_releases]

    releases = list(release_queryset)

    # Add SBOMs from releases
    for release in releases:
        for artifact in release.artifacts.filter(sbom__isnull=False):
            sbom = artifact.sbom
            if sbom.id not in sboms_to_scan:
                sboms_to_scan[sbom.id] = (sbom, "release", f"{release.product.name} v{release.name}")

    # 2. Get latest SBOMs from all components
    component_queryset = Component.objects.select_related("team").prefetch_related("sbom_set")

    # Filter by team if specified
    if team_key:
        component_queryset = component_queryset.filter(team__key=team_key)

    # Only get components that have SBOMs
    component_queryset = component_queryset.filter(sbom__isnull=False).distinct()

    components = list(component_queryset)

    # Add latest SBOMs from components (if not already included)
    for component in components:
        latest_sbom = component.latest_sbom
        if latest_sbom and latest_sbom.id not in sboms_to_scan:
            sboms_to_scan[latest_sbom.id] = (latest_sbom, "component_latest", f"{component.name}")

    logger.info(
        f"[TASK_weekly_vulnerability_scan] Found {len(releases)} releases and {len(components)} components. "
        f"Total unique SBOMs to scan: {len(sboms_to_scan)}"
    )

    return {
        "sboms": list(sboms_to_scan.values()),
        "total_releases": len(releases),
        "total_components": len(components),
        "total_unique_sboms": len(sboms_to_scan),
    }


def _perform_comprehensive_scans(scan_targets: Dict[str, Any], force_rescan: bool) -> Dict[str, Any]:
    """Perform vulnerability scans on all collected SBOMs."""
    sboms_list = scan_targets["sboms"]
    results = {
        "total_releases": scan_targets["total_releases"],
        "total_components": scan_targets["total_components"],
        "total_sboms": len(sboms_list),
        "successful_scans": 0,
        "failed_scans": 0,
        "skipped_scans": 0,
        "errors": [],
        "provider_stats": {},
        "source_stats": {},  # Track scans by source type (release vs component_latest)
    }

    service = VulnerabilityScanningService()

    for i, (sbom, source_type, source_info) in enumerate(sboms_list, 1):
        logger.info(
            f"[TASK_weekly_vulnerability_scan] [{i}/{len(sboms_list)}] Scanning {sbom.name} "
            f"({source_type}: {source_info})..."
        )

        team = sbom.component.team

        # Check if team has vulnerability scanning enabled
        if not _team_has_vulnerability_scanning(team):
            logger.info(f"[TASK_weekly_vulnerability_scan] Skipping {team.key} - no vulnerability scanning plan")
            results["skipped_scans"] += 1
            continue

        try:
            # Check if recent scan exists (unless force rescan)
            if not force_rescan and _has_recent_scan(sbom):
                logger.info(f"[TASK_weekly_vulnerability_scan] Skipping {sbom.name} - recent scan exists")
                results["skipped_scans"] += 1
                continue

            # Perform scan with appropriate trigger based on source
            scan_trigger = "weekly" if source_type == "release" else "component_latest"
            scan_result = _scan_sbom_comprehensive(sbom, service, scan_trigger)

            if scan_result and scan_result.get("status") != "error":
                results["successful_scans"] += 1
                provider = scan_result.get("provider", "unknown")
                results["provider_stats"][provider] = results["provider_stats"].get(provider, 0) + 1
                results["source_stats"][source_type] = results["source_stats"].get(source_type, 0) + 1
                logger.info(
                    f"[TASK_weekly_vulnerability_scan] Successfully scanned {sbom.name} with {provider} "
                    f"(source: {source_type})"
                )
            else:
                results["failed_scans"] += 1
                error_msg = scan_result.get("error", "Unknown error") if scan_result else "Scan returned None"
                results["errors"].append(f"Failed to scan {sbom.name}: {error_msg}")
                logger.error(f"[TASK_weekly_vulnerability_scan] Failed to scan {sbom.name}: {error_msg}")

        except Exception as e:
            results["failed_scans"] += 1
            error_msg = f"Failed to scan {sbom.name}: {e}"
            results["errors"].append(error_msg)
            logger.exception(f"[TASK_weekly_vulnerability_scan] {error_msg}")

    logger.info(f"[TASK_weekly_vulnerability_scan] Scan breakdown by source: {results['source_stats']}")

    return results


def _team_has_vulnerability_scanning(team) -> bool:
    """Check if team has vulnerability scanning enabled."""
    # OSV vulnerability scanning is available for ALL teams (community, business, enterprise)
    # The VulnerabilityScanningService will handle provider selection:
    # - Community teams: OSV only
    # - Business/Enterprise teams: OSV or Dependency Track based on team settings
    return True


def _has_recent_scan(sbom: SBOM) -> bool:
    """Check if SBOM has been scanned recently (within 24 hours)."""
    cutoff = timezone.now() - timedelta(hours=24)
    return VulnerabilityScanResult.objects.filter(sbom=sbom, created_at__gte=cutoff).exists()


def _scan_sbom_comprehensive(sbom: SBOM, service: VulnerabilityScanningService, scan_trigger: str) -> Dict[str, Any]:
    """Scan a single SBOM for vulnerabilities in comprehensive scanning context."""
    try:
        # Use shared utility for SBOM data fetching
        _, sbom_data = get_sbom_data_bytes(str(sbom.id))

        # Perform scan with appropriate trigger
        scan_result = service.scan_sbom_for_vulnerabilities(sbom=sbom, sbom_data=sbom_data, scan_trigger=scan_trigger)

        return {
            "status": "success",
            "provider": scan_result.get("provider", "unknown"),
            "summary": scan_result.get("summary", {}),
            "sbom_id": str(sbom.id),
            "scan_trigger": scan_trigger,
        }

    except SBOMDataError as e:
        logger.warning(f"[TASK_weekly_vulnerability_scan] {e}")
        return {"status": "error", "error": str(e)}
    except Exception:
        logger.exception(f"[TASK_weekly_vulnerability_scan] Failed to scan SBOM {sbom.id}")
        return {"status": "error", "error": "Processing error"}


@cron("0 */6 * * *")  # Run every 6 hours
@dramatiq.actor(queue_name="dt_health_check", max_retries=2, time_limit=60000, store_results=True)
@retry(
    retry=retry_if_exception_type((OperationalError, DatabaseError)),
    wait=wait_exponential(multiplier=1, min=1, max=5),
    stop=stop_after_delay(30),
    before_sleep=before_sleep_log(logger, logging.WARNING),
)
def check_dependency_track_health_task(server_id: str = None) -> Dict[str, Any]:
    """
    Task to check Dependency Track server health and update status - runs every 6 hours.

    Args:
        server_id: Specific server ID to check. If None, checks all active servers.

    Returns:
        Health check results
    """
    logger.info("[TASK_check_dependency_track_health] Starting DT health check task")

    try:
        with transaction.atomic():
            connection.ensure_connection()

            from .models import DependencyTrackServer
            from .services import VulnerabilityScanningService

            service = VulnerabilityScanningService()

            if server_id:
                # Check specific server
                try:
                    server = DependencyTrackServer.objects.get(id=server_id)
                    result = service.check_dependency_track_server_health(server)
                    logger.info(f"[TASK_check_dependency_track_health] Health check completed for server {server.name}")
                    return {
                        "status": "completed",
                        "servers_checked": 1,
                        "results": [result],
                        "completed_at": timezone.now().isoformat(),
                    }
                except DependencyTrackServer.DoesNotExist:
                    logger.error(f"[TASK_check_dependency_track_health] Server with ID {server_id} not found")
                    return {
                        "status": "error",
                        "error": f"Server with ID {server_id} not found",
                        "failed_at": timezone.now().isoformat(),
                    }
            else:
                # Check all active servers
                results = service.check_all_dependency_track_servers_health()
                healthy_count = sum(1 for r in results if r["status"] == "healthy")
                unhealthy_count = len(results) - healthy_count

                logger.info(
                    f"[TASK_check_dependency_track_health] Health check completed for {len(results)} servers. "
                    f"Healthy: {healthy_count}, Unhealthy: {unhealthy_count}"
                )

                return {
                    "status": "completed",
                    "servers_checked": len(results),
                    "healthy_servers": healthy_count,
                    "unhealthy_servers": unhealthy_count,
                    "results": results,
                    "completed_at": timezone.now().isoformat(),
                }

    except Exception:
        logger.exception("[TASK_check_dependency_track_health] DT health check task failed")
        return {"status": "failed", "error": "Task failed", "failed_at": timezone.now().isoformat()}


@dramatiq.actor(queue_name="dt_polling", max_retries=0, time_limit=300000, store_results=True)
@retry(
    retry=retry_if_exception_type((OperationalError, DatabaseError)),
    wait=wait_exponential(multiplier=1, min=1, max=5),
    stop=stop_after_delay(30),
    before_sleep=before_sleep_log(logger, logging.WARNING),
)
def poll_dependency_track_results_task(
    sbom_id: str, mapping_id: str, max_attempts: int = 6, initial_delay: int = 30, current_attempt: int = 1
) -> Dict[str, Any]:
    """
    Poll Dependency Track for vulnerability scan results.

    This task waits for DT to process the uploaded SBOM and then fetches
    the vulnerability results when they're ready.

    Args:
        sbom_id: SBOM ID to check results for
        mapping_id: ComponentDependencyTrackMapping ID
        max_attempts: Maximum number of polling attempts
        initial_delay: Initial delay before first check (seconds)
        current_attempt: Current attempt number

    Returns:
        Dictionary with polling results
    """
    import time

    from .models import ComponentDependencyTrackMapping

    logger.info(f"[TASK_poll_dt_results] Attempt {current_attempt}/{max_attempts} for SBOM {sbom_id}")

    try:
        # Wait for the specified delay before checking
        if current_attempt == 1:
            delay = initial_delay
        else:
            # Exponential backoff: 30s, 60s, 120s, 240s, 480s, 960s
            delay = initial_delay * (2 ** (current_attempt - 1))
            delay = min(delay, 960)  # Cap at 16 minutes

        logger.info(f"[TASK_poll_dt_results] Waiting {delay} seconds before checking SBOM {sbom_id}")
        time.sleep(delay)

        with transaction.atomic():
            connection.ensure_connection()

            # Get SBOM and mapping
            sbom = SBOM.objects.get(id=sbom_id)
            mapping = ComponentDependencyTrackMapping.objects.get(id=mapping_id)

            # Check if DT has processed the SBOM
            service = VulnerabilityScanningService()

            try:
                # Try to get results from DT
                scan_results = service.get_dependency_track_results(sbom, mapping, force_refresh=True)

                # Check if we got meaningful results (DT has processed the SBOM)
                total_vulns = scan_results.get("vulnerability_count", {}).get("total", 0)
                scan_results.get("findings", [])

                # Consider it processed if we have vulnerability data OR if the project exists and returns zero vulns
                # (some SBOMs legitimately have no vulnerabilities)
                project_exists = scan_results.get("metrics") is not None

                if project_exists:
                    # DT has processed the SBOM, store final results
                    logger.info(
                        f"[TASK_poll_dt_results] DT processing complete for SBOM {sbom_id}. "
                        f"Found {total_vulns} vulnerabilities"
                    )

                    # Store the final results in the database
                    service._cache_dt_results(sbom, mapping, scan_results)

                    return {
                        "status": "completed",
                        "sbom_id": sbom_id,
                        "attempt": current_attempt,
                        "total_vulnerabilities": total_vulns,
                        "processing_time_seconds": delay * current_attempt,
                        "message": f"Vulnerability scan completed. Found {total_vulns} vulnerabilities.",
                        "completed_at": timezone.now().isoformat(),
                    }
                else:
                    # DT hasn't finished processing yet
                    if current_attempt >= max_attempts:
                        # Max attempts reached, give up
                        logger.warning(
                            f"[TASK_poll_dt_results] Max attempts ({max_attempts}) reached for SBOM {sbom_id}"
                        )

                        # Store a timeout result
                        timeout_results = {
                            "vulnerability_count": {
                                "critical": 0,
                                "high": 0,
                                "medium": 0,
                                "low": 0,
                                "info": 0,
                                "total": 0,
                            },
                            "findings": [],
                            "error": "Dependency Track processing timeout",
                            "scan_metadata": {"timeout": True, "attempts": max_attempts},
                        }
                        service._cache_dt_results(sbom, mapping, timeout_results)

                        return {
                            "status": "timeout",
                            "sbom_id": sbom_id,
                            "attempt": current_attempt,
                            "message": "Dependency Track processing timeout after maximum attempts",
                            "failed_at": timezone.now().isoformat(),
                        }
                    else:
                        # Schedule next attempt
                        logger.info(
                            f"[TASK_poll_dt_results] DT still processing SBOM {sbom_id}, "
                            f"scheduling attempt {current_attempt + 1}"
                        )
                        poll_dependency_track_results_task.send(
                            sbom_id, mapping_id, max_attempts, initial_delay, current_attempt + 1
                        )

                        return {
                            "status": "polling",
                            "sbom_id": sbom_id,
                            "attempt": current_attempt,
                            "next_attempt_in_seconds": delay * 2,
                            "message": f"DT still processing, will check again in {delay * 2} seconds",
                        }

            except Exception as api_error:
                logger.warning(f"[TASK_poll_dt_results] API error for SBOM {sbom_id}: {api_error}")

                if current_attempt >= max_attempts:
                    # Max attempts reached with API errors
                    error_results = {
                        "vulnerability_count": {"critical": 0, "high": 0, "medium": 0, "low": 0, "info": 0, "total": 0},
                        "findings": [],
                        "error": f"DT API error: {str(api_error)}",
                        "scan_metadata": {"api_error": True, "attempts": max_attempts},
                    }
                    service._cache_dt_results(sbom, mapping, error_results)

                    return {
                        "status": "error",
                        "sbom_id": sbom_id,
                        "attempt": current_attempt,
                        "error": str(api_error),
                        "failed_at": timezone.now().isoformat(),
                    }
                else:
                    # Retry on API error
                    poll_dependency_track_results_task.send(
                        sbom_id, mapping_id, max_attempts, initial_delay, current_attempt + 1
                    )

                    return {
                        "status": "retrying",
                        "sbom_id": sbom_id,
                        "attempt": current_attempt,
                        "error": str(api_error),
                        "message": "API error, will retry",
                    }

    except SBOM.DoesNotExist:
        logger.error(f"[TASK_poll_dt_results] SBOM {sbom_id} not found")
        return {
            "status": "error",
            "sbom_id": sbom_id,
            "error": "SBOM not found",
            "failed_at": timezone.now().isoformat(),
        }
    except Exception:
        logger.exception(f"[TASK_poll_dt_results] Unexpected error for SBOM {sbom_id}")
        return {
            "status": "error",
            "sbom_id": sbom_id,
            "error": "Processing error",
            "failed_at": timezone.now().isoformat(),
        }


@cron("0 */6 * * *")  # Run every 6 hours at minute 0
@dramatiq.actor(queue_name="dt_periodic_polling", max_retries=2, time_limit=1800000, store_results=True)
@retry(
    retry=retry_if_exception_type((OperationalError, DatabaseError)),
    wait=wait_exponential(multiplier=1, min=2, max=10),
    stop=stop_after_delay(60),
    before_sleep=before_sleep_log(logger, logging.WARNING),
)
def periodic_dependency_track_polling_task(hours_back: int = 6) -> Dict[str, Any]:
    """
    Periodic task to poll Dependency Track for vulnerability updates on existing projects - runs every 6 hours.

    This task runs every 6 hours to check for new vulnerabilities on existing DT projects
    without re-uploading SBOMs. DT continuously monitors for new CVEs, so we need to
    poll regularly to get updated vulnerability data.

    Args:
        hours_back: Only poll projects that haven't been checked in the last N hours

    Returns:
        Dictionary with polling statistics and results
    """
    from datetime import timedelta

    from django.db import models

    from .models import ComponentDependencyTrackMapping
    from .services import VulnerabilityScanningService

    logger.info(f"[TASK_dt_periodic_polling] Starting periodic DT polling (last {hours_back}h)")

    try:
        with transaction.atomic():
            connection.ensure_connection()

            # Find DT mappings that haven't been polled recently
            recent_threshold = timezone.now() - timedelta(hours=hours_back)

            # Get mappings that either:
            # 1. Haven't been synced recently, OR
            # 2. Have been uploaded but not polled in the last N hours
            stale_mappings = (
                ComponentDependencyTrackMapping.objects.filter(
                    dt_server__is_active=True, dt_server__health_status__in=["healthy", "degraded"]
                )
                .filter(models.Q(last_metrics_sync__lt=recent_threshold) | models.Q(last_metrics_sync__isnull=True))
                .select_related("component", "dt_server")
            )

            if not stale_mappings.exists():
                logger.info("[TASK_dt_periodic_polling] No stale DT mappings found")
                return {
                    "status": "completed",
                    "mappings_checked": 0,
                    "successful_polls": 0,
                    "failed_polls": 0,
                    "message": "No mappings needed polling",
                }

            results = {
                "status": "completed",
                "mappings_checked": stale_mappings.count(),
                "successful_polls": 0,
                "failed_polls": 0,
                "errors": [],
                "updated_projects": [],
            }

            for mapping in stale_mappings[:50]:  # Limit to 50 per run to avoid overload
                service = VulnerabilityScanningService()
                try:
                    # Get the latest SBOM for this component
                    latest_sbom = mapping.component.sbom_set.order_by("-created_at").first()

                    if not latest_sbom:
                        logger.warning(
                            f"[TASK_dt_periodic_polling] No SBOMs found for component {mapping.component.id}"
                        )
                        continue

                    logger.debug(
                        f"[TASK_dt_periodic_polling] Polling {mapping.component.name} project {mapping.dt_project_name}"
                    )

                    # Poll for updated vulnerability data
                    poll_results = service.get_dependency_track_results(latest_sbom, mapping, force_refresh=True)

                    # Store the updated results
                    service._cache_dt_results(latest_sbom, mapping, poll_results)

                    # Update the sync timestamp
                    mapping.last_metrics_sync = timezone.now()
                    mapping.save(update_fields=["last_metrics_sync"])

                    results["successful_polls"] += 1
                    results["updated_projects"].append(
                        {
                            "component": mapping.component.name,
                            "project_uuid": str(mapping.dt_project_uuid),
                            "vulnerabilities": poll_results.get("vulnerability_count", {}).get("total", 0),
                        }
                    )

                    logger.debug(f"[TASK_dt_periodic_polling] Successfully polled {mapping.component.name}")

                except Exception as poll_error:
                    logger.warning(f"[TASK_dt_periodic_polling] Failed to poll mapping {mapping.id}: {poll_error}")
                    results["failed_polls"] += 1
                    results["errors"].append({"component": mapping.component.name, "error": str(poll_error)})

            logger.info(
                f"[TASK_dt_periodic_polling] Completed periodic polling. "
                f"Checked {results['mappings_checked']} mappings, "
                f"{results['successful_polls']} successful, {results['failed_polls']} failed"
            )

            return results

    except Exception:
        logger.exception("[TASK_dt_periodic_polling] Periodic DT polling failed")
        return {"status": "failed", "error": "Task failed", "failed_at": timezone.now().isoformat()}


@cron("0 * * * *")  # Run every hour at minute 0
@dramatiq.actor(queue_name="dt_hourly_setup", max_retries=2, time_limit=900000, store_results=True)
@retry(
    retry=retry_if_exception_type((OperationalError, DatabaseError)),
    wait=wait_exponential(multiplier=1, min=2, max=15),
    stop=stop_after_delay(120),
    before_sleep=before_sleep_log(logger, logging.WARNING),
)
def recurring_dependency_track_backfill_task(
    team_key: str = None, max_components: int = 50, dry_run: bool = False
) -> Dict[str, Any]:
    """
    Hourly scheduled task to ensure components from teams using DT have proper mappings and uploaded SBOMs.

    Automatically runs every hour to quickly handle cases where:
    - Teams upgrade billing plans (Community → Business/Enterprise)
    - Teams switch vulnerability provider (OSV → Dependency Track)
    - Teams add custom DT servers (Enterprise feature)
    - Components exist that should use DT but have no ComponentDependencyTrackMapping

    These components are ignored by periodic polling since it only works on existing mappings.

    Strategy:
    1. Find components belonging to teams configured for DT
    2. Filter to components that have NO DT mappings yet
    3. Upload latest SBOM + SBOMs from tagged releases (same logic as weekly scan)
    4. Rate-limited to 50 components per hour to avoid overwhelming DT servers

    Args:
        team_key: Only process components for a specific team (for testing)
        max_components: Maximum number of components to process per run (default: 50)
        dry_run: If True, only identify components without uploading

    Returns:
        Dictionary with setup statistics and results
    """
    logger.info(f"[TASK_dt_hourly_setup] Starting hourly DT component check (dry_run={dry_run})")

    try:
        connection.ensure_connection()

        from .services import DependencyTrackSetupService

        # Use the dedicated service for DT setup operations
        setup_service = DependencyTrackSetupService()

        # Find components that need DT setup
        components_needing_setup = setup_service.find_components_needing_setup(team_key, max_components)

        if not components_needing_setup:
            logger.info("[TASK_dt_hourly_setup] No components found that need DT setup")
            return {
                "status": "completed",
                "dry_run": dry_run,
                "components_identified": 0,
                "sboms_processed": 0,
                "successful_uploads": 0,
                "failed_uploads": 0,
                "message": "No components need DT setup",
            }

        if dry_run:
            # Just report what would be processed
            logger.info(f"[TASK_dt_hourly_setup] DRY RUN: Would process {len(components_needing_setup)} components")
            return {
                "status": "completed",
                "dry_run": True,
                "components_identified": len(components_needing_setup),
                "components": [
                    {
                        "id": str(comp.id),
                        "name": comp.name,
                        "team": comp.team.key,
                        "sbom_count": comp.sbom_set.count(),
                        "latest_sbom_date": comp.latest_sbom.created_at.isoformat() if comp.latest_sbom else None,
                    }
                    for comp in components_needing_setup
                ],
            }

        # Process components using the service
        results = setup_service.process_components_for_setup(components_needing_setup)

        logger.info(
            f"[TASK_dt_hourly_setup] Recurring check completed in {results['processing_time_ms']}ms. "
            f"Processed {results['components_processed']} components, "
            f"{results['successful_uploads']} successful uploads, "
            f"{results['failed_uploads']} failed uploads. "
            f"Performance: avg download {results['performance_metrics']['avg_sbom_download_time_ms']}ms, "
            f"avg upload {results['performance_metrics']['avg_upload_time_ms']}ms, "
            f"total data {results['performance_metrics']['total_data_processed_bytes']} bytes"
        )

        return {"status": "completed", "dry_run": False, **results}

    except Exception as e:
        logger.exception(f"[TASK_dt_hourly_setup] Recurring DT component check failed: {e}")
        return {"status": "failed", "error": f"Task failed: {str(e)}", "failed_at": timezone.now().isoformat()}


# Helper functions have been moved to DependencyTrackSetupService in services.py
# to improve code organization and maintainability
