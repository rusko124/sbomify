"""Dependency Track API client for vulnerability scanning integration."""

import json
import logging
import os
import subprocess
import tempfile
from typing import Any, Dict, List, Optional
from urllib.parse import urljoin

import requests
from django.conf import settings

logger = logging.getLogger(__name__)


class VulnerabilityProviderError(Exception):
    """Exception raised for vulnerability provider errors."""

    def __init__(self, message: str, status_code: Optional[int] = None, response_data: Optional[Dict] = None):
        self.status_code = status_code
        self.response_data = response_data
        super().__init__(message)


class OSVClient:
    """
    Client for interacting with OSV scanner.

    Handles SBOM scanning using the osv-scanner binary.
    """

    def __init__(self, timeout: int = None):
        """
        Initialize the OSV client.

        Args:
            timeout: Scanner timeout in seconds (defaults to settings.OSV_SCANNER_TIMEOUT_SECONDS)
        """
        self.timeout = timeout or getattr(settings, "OSV_SCANNER_TIMEOUT_SECONDS", 300)
        self.scanner_path = "/usr/local/bin/osv-scanner"  # As defined in Dockerfile

    def scan_sbom(self, sbom_data: bytes, sbom_filename: str = None) -> Dict[str, Any]:
        """
        Scan an SBOM for vulnerabilities using osv-scanner.

        Args:
            sbom_data: SBOM file content as bytes
            sbom_filename: Original filename for format detection

        Returns:
            Scan results as dictionary

        Raises:
            VulnerabilityProviderError: If the scan fails
        """
        temp_sbom_file = None

        try:
            # Determine file suffix for proper format detection
            file_suffix = self._determine_file_suffix(sbom_data, sbom_filename)

            # Create temporary file
            with tempfile.NamedTemporaryFile(delete=False, mode="wb", suffix=file_suffix) as temp_file:
                temp_sbom_file = temp_file.name
                temp_file.write(sbom_data)

            # Validate SBOM content
            self._validate_sbom_content(sbom_data)

            # Execute osv-scanner
            scan_command = [
                self.scanner_path,
                "scan",
                "source",  # Using "scan source" as it worked in local tests
                "--sbom",
                temp_sbom_file,
                "--format",
                "json",
            ]

            logger.debug(f"[OSV_SCAN] Executing command: {' '.join(scan_command)}")

            try:
                process = subprocess.run(scan_command, capture_output=True, text=True, timeout=self.timeout)

                # Handle stderr output
                self._handle_scanner_stderr(process)

                # Check for valid exit codes (0 = no vulnerabilities, 1 = vulnerabilities found)
                if process.returncode not in [0, 1]:
                    raise subprocess.CalledProcessError(
                        process.returncode, scan_command, process.stdout, process.stderr
                    )

                # Parse and return results
                return self._parse_scan_results(process.stdout)

            except subprocess.TimeoutExpired:
                error_data = {
                    "error": "Vulnerability scan timed out",
                    "details": (
                        f"The scan exceeded the maximum allowed time of {self.timeout} seconds. "
                        f"This may indicate a very large SBOM or slow network connectivity to vulnerability databases."
                    ),
                    "timeout_seconds": self.timeout,
                    "provider": "osv",
                }
                raise VulnerabilityProviderError("OSV scan timed out", response_data=error_data)

        except subprocess.CalledProcessError as e:
            error_detail = {
                "error": "osv-scanner execution failed",
                "return_code": e.returncode,
                "stdout": e.stdout,
                "stderr": e.stderr,
                "provider": "osv",
            }
            raise VulnerabilityProviderError(f"OSV scanner failed: {e.stderr}", response_data=error_detail)

        except Exception as e:
            raise VulnerabilityProviderError(f"OSV scan failed: {str(e)}")

        finally:
            # Clean up temporary file
            if temp_sbom_file and os.path.exists(temp_sbom_file):
                os.remove(temp_sbom_file)
                logger.debug(f"[OSV_SCAN] Cleaned up temporary file: {temp_sbom_file}")

    def _determine_file_suffix(self, sbom_data: bytes, sbom_filename: str = None) -> str:
        """
        Determine appropriate file suffix for OSV scanner compatibility.

        IMPORTANT: This method determines the FILE SUFFIX for the OSV scanner,
        NOT the actual SBOM format. Format determination MUST be done by parsing
        the actual JSON content, never by filename patterns.

        The suffix helps OSV scanner optimize its parsing, but format routing
        decisions should always be based on content analysis.
        """
        # Always parse content to determine the actual format
        try:
            content = json.loads(sbom_data.decode("utf-8"))
            if content.get("bomFormat") == "CycloneDX":
                logger.debug("[OSV_SCAN] Content is CycloneDX - using .cdx.json suffix for OSV scanner")
                return ".cdx.json"
            elif content.get("spdxVersion"):
                logger.debug(
                    f"[OSV_SCAN] Content is SPDX (version: {content.get('spdxVersion')}) - "
                    "using .spdx.json suffix for OSV scanner"
                )
                return ".spdx.json"
        except Exception as e:
            logger.warning(f"[OSV_SCAN] Failed to parse SBOM content for format detection: {e}")

        # Fallback: use generic suffix if content parsing fails
        logger.warning("[OSV_SCAN] Could not determine SBOM format from content, using generic .json suffix")
        return ".json"

    def _validate_sbom_content(self, sbom_data: bytes) -> None:
        """
        Validate SBOM content and detect format.

        IMPORTANT: Validates that we have a proper SBOM (either CycloneDX or SPDX).
        These formats are incompatible - CycloneDX tools cannot parse SPDX and vice versa.
        """
        try:
            content = json.loads(sbom_data.decode("utf-8"))

            # Check for CycloneDX format
            if content.get("bomFormat") == "CycloneDX":
                logger.debug(f"[OSV_SCAN] Valid CycloneDX SBOM (version: {content.get('specVersion', 'unknown')})")
                return

            # Check for SPDX format
            if content.get("spdxVersion"):
                logger.debug(f"[OSV_SCAN] Valid SPDX SBOM (version: {content.get('spdxVersion')})")
                return

            # Not a recognized SBOM format
            logger.warning(
                "[OSV_SCAN] Content appears to be JSON but not a recognized SBOM format "
                "(missing bomFormat or spdxVersion)"
            )
            # Continue anyway - OSV scanner may still be able to process it

        except (json.JSONDecodeError, UnicodeDecodeError) as e:
            error_msg = (
                f"OSV scan failed: SBOM content is not valid JSON or has encoding issues. "
                f"Error: {e}. First 200 chars: {sbom_data[:200]}"
            )
            raise VulnerabilityProviderError(error_msg)

    def _handle_scanner_stderr(self, process: subprocess.CompletedProcess) -> None:
        """Handle and log stderr output from osv-scanner."""
        stderr_content = process.stderr.strip() if process.stderr else ""

        if stderr_content:
            if process.returncode in [0, 1]:  # Success or success with findings
                lines = stderr_content.split("\n")
                is_purely_informational = all(
                    not line.strip()
                    or "Neither CPE nor PURL found for package" in line
                    or ("Filtered" in line and "package/s from the scan" in line)
                    or ("Scanned" in line and "file and found" in line and "package" in line)
                    for line in lines
                )

                if is_purely_informational:
                    logger.debug(f"[OSV_SCAN] Informational output (code {process.returncode}): {stderr_content}")
                else:
                    logger.warning(f"[OSV_SCAN] Warning output (code {process.returncode}): {stderr_content}")
            else:
                logger.warning(f"[OSV_SCAN] Error output (code {process.returncode}): {stderr_content}")

    def _parse_scan_results(self, stdout: str) -> Dict[str, Any]:
        """Parse osv-scanner JSON output into standardized format."""
        if not stdout:
            return {
                "vulnerability_count": {
                    "total": 0,
                    "critical": 0,
                    "high": 0,
                    "medium": 0,
                    "low": 0,
                    "info": 0,
                    "unknown": 0,
                },
                "findings": {"vulnerabilities": []},
                "provider": "osv",
                "raw_output": "",
            }

        try:
            raw_results = json.loads(stdout)

            # Count vulnerabilities by severity
            vuln_counts = {"critical": 0, "high": 0, "medium": 0, "low": 0, "info": 0, "unknown": 0, "total": 0}

            # Process vulnerabilities
            processed_vulns = []
            results = raw_results.get("results", [])

            for result in results:
                packages = result.get("packages", [])
                for package in packages:
                    vulnerabilities = package.get("vulnerabilities", [])
                    for vuln in vulnerabilities:
                        vuln_counts["total"] += 1

                        # Map OSV severity to our standard levels
                        severity = self._map_osv_severity(vuln)
                        if severity in vuln_counts:
                            vuln_counts[severity] += 1

                        processed_vulns.append(
                            {
                                "id": vuln.get("id"),
                                "source": "OSV",
                                "severity": severity,
                                "title": vuln.get("summary"),
                                "description": vuln.get("details"),
                                "references": [ref.get("url") for ref in vuln.get("references", []) if ref.get("url")],
                                "aliases": vuln.get("aliases", []),
                                "package_name": package.get("package", {}).get("name"),
                                "component": {
                                    "name": package.get("package", {}).get("name"),
                                    "version": package.get("package", {}).get("version"),
                                    "ecosystem": package.get("package", {}).get("ecosystem"),
                                },
                                "affected": vuln.get("affected", []),
                            }
                        )

            return {
                "vulnerability_count": vuln_counts,
                "findings": {"vulnerabilities": processed_vulns},
                "provider": "osv",
                "raw_output": stdout,
                "scan_summary": f"Found {vuln_counts['total']} vulnerabilities across {len(results)} result groups",
            }

        except json.JSONDecodeError as e:
            logger.error(f"[OSV_SCAN] Failed to parse scanner output as JSON: {e}")
            return {
                "vulnerability_count": {"total": 0},
                "findings": [],
                "provider": "osv",
                "raw_output": stdout,
                "parse_error": str(e),
            }

    def _map_osv_severity(self, vuln: Dict[str, Any]) -> str:
        """Map OSV vulnerability data to severity level."""
        # OSV doesn't always provide explicit severity, so we need to infer it

        # Check for direct severity field (common in OSV format)
        if "severity" in vuln:
            for severity_item in vuln.get("severity", []):
                if severity_item.get("type") == "CVSS_V3":
                    cvss_score = severity_item.get("score", "")
                    if cvss_score.startswith("CVSS:3."):
                        # Parse CVSS v3 score to determine severity
                        try:
                            # Extract the score from CVSS string
                            import re

                            score_match = re.search(
                                r"CVSS:3\.\d+/AV:[A-Z]/AC:[A-Z]/PR:[A-Z]/UI:[A-Z]/S:[A-Z]/C:[A-Z]/I:[A-Z]/A:[A-Z]",
                                cvss_score,
                            )
                            if score_match:
                                # This is a maximum severity CVSS (10.0)
                                if "C:H/I:H/A:H" in cvss_score and "S:C" in cvss_score:
                                    return "critical"
                                elif "C:H/I:H/A:H" in cvss_score:
                                    return "high"
                                elif "C:M" in cvss_score or "I:M" in cvss_score or "A:M" in cvss_score:
                                    return "medium"
                                elif "C:L" in cvss_score or "I:L" in cvss_score or "A:L" in cvss_score:
                                    return "low"
                        except (KeyError, ValueError, TypeError) as e:
                            # Unable to parse severity, default to unknown
                            logger.debug(f"Failed to parse CVSS score {cvss_score}: {e}")
                            continue

        # Check for explicit severity in database_specific
        for affected in vuln.get("affected", []):
            for range_item in affected.get("ranges", []):
                db_specific = range_item.get("database_specific", {})
                if "severity" in db_specific:
                    severity = db_specific["severity"]
                    if isinstance(severity, list) and severity:
                        return severity[0].lower()
                    elif isinstance(severity, str):
                        return severity.lower()

        # Check CVSS scores in database_specific
        severity_scores = []
        for affected in vuln.get("affected", []):
            for range_item in affected.get("ranges", []):
                db_specific = range_item.get("database_specific", {})
                cvss_score = db_specific.get("cvss_score") or db_specific.get("cvss_v3_score")
                if cvss_score:
                    try:
                        score = float(cvss_score)
                        if score >= 9.0:
                            severity_scores.append("critical")
                        elif score >= 7.0:
                            severity_scores.append("high")
                        elif score >= 4.0:
                            severity_scores.append("medium")
                        else:
                            severity_scores.append("low")
                    except (ValueError, TypeError):
                        pass

        if severity_scores:
            # Return highest severity found
            severity_order = ["critical", "high", "medium", "low"]
            for sev in severity_order:
                if sev in severity_scores:
                    return sev

        # Default to medium if we can't determine severity
        return "medium"

    def detect_sbom_format(self, sbom_data: bytes) -> str:
        """
        Detect SBOM format by parsing content.

        CRITICAL: This is the authoritative method for format detection.
        Never use filenames, extensions, or other heuristics for format routing.

        Args:
            sbom_data: SBOM file content as bytes

        Returns:
            Format string: "cyclonedx", "spdx", or "unknown"
        """
        try:
            content = json.loads(sbom_data.decode("utf-8"))

            # Check for CycloneDX format
            if content.get("bomFormat") == "CycloneDX":
                return "cyclonedx"

            # Check for SPDX format
            if content.get("spdxVersion"):
                return "spdx"

            # Not a recognized SBOM format
            return "unknown"

        except (json.JSONDecodeError, UnicodeDecodeError):
            return "unknown"


class DependencyTrackAPIError(Exception):
    """Exception raised for Dependency Track API errors."""

    def __init__(self, message: str, status_code: Optional[int] = None, response_data: Optional[Dict] = None):
        self.status_code = status_code
        self.response_data = response_data
        super().__init__(message)


class DependencyTrackClient:
    """
    Client for interacting with Dependency Track API.

    Handles authentication, project management, SBOM uploads, and vulnerability retrieval.
    """

    def __init__(self, base_url: str, api_key: str, timeout: int = 30):
        """
        Initialize the Dependency Track client.

        Args:
            base_url: Base URL of the Dependency Track server
            api_key: API key for authentication
            timeout: Request timeout in seconds
        """
        self.base_url = base_url.rstrip("/")
        self.api_key = api_key
        self.timeout = timeout
        self.session = requests.Session()
        self.session.headers.update(
            {
                "X-Api-Key": api_key,
                "Accept": "application/json",
            }
        )

    def _make_request(
        self,
        method: str,
        endpoint: str,
        data: Optional[Dict] = None,
        files: Optional[Dict] = None,
        params: Optional[Dict] = None,
    ) -> Dict[str, Any]:
        """
        Make an HTTP request to the Dependency Track API.

        Args:
            method: HTTP method (GET, POST, PUT, DELETE)
            endpoint: API endpoint (without base URL)
            data: JSON data to send
            files: Files to upload
            params: Query parameters

        Returns:
            Response data as dictionary

        Raises:
            DependencyTrackAPIError: If the request fails
        """
        # Health endpoints are on the root path, not under /api
        if endpoint.startswith("/health") or endpoint == "/version":
            url = urljoin(f"{self.base_url}/", endpoint.lstrip("/"))
        else:
            url = urljoin(f"{self.base_url}/api/", endpoint.lstrip("/"))

        try:
            # Handle file uploads differently
            if files:
                # For file uploads, let requests handle the multipart Content-Type
                response = self.session.request(
                    method=method, url=url, data=data, files=files, params=params, timeout=self.timeout
                )
            else:
                # For JSON requests, set Content-Type header
                headers = self.session.headers.copy()
                headers["Content-Type"] = "application/json"
                response = self.session.request(
                    method=method, url=url, json=data, params=params, timeout=self.timeout, headers=headers
                )

            logger.debug(f"DT API {method} {url} -> {response.status_code}")

            if response.status_code == 204:  # No content
                return {}

            if not response.ok:
                error_msg = f"DT API request failed: {response.status_code}"
                try:
                    error_data = response.json()
                    error_msg += f" - {error_data}"
                except (ValueError, json.JSONDecodeError):
                    error_msg += f" - {response.text}"

                raise DependencyTrackAPIError(
                    error_msg,
                    status_code=response.status_code,
                    response_data=response.json() if response.content else None,
                )

            response_data = response.json() if response.content else {}

            # For pagination support, include X-Total-Count header if present
            if "X-Total-Count" in response.headers:
                if isinstance(response_data, list):
                    # If response is a list, wrap it with pagination metadata
                    response_data = {
                        "content": response_data,
                        "totalElements": int(response.headers["X-Total-Count"]),
                        "paginated": True,
                    }
                elif isinstance(response_data, dict):
                    # If response is a dict, add pagination metadata
                    response_data["totalElements"] = int(response.headers["X-Total-Count"])
                    response_data["paginated"] = True

            return response_data

        except requests.exceptions.RequestException as e:
            raise DependencyTrackAPIError(f"Request failed: {str(e)}")

    def _make_paginated_request(
        self,
        endpoint: str,
        params: Optional[Dict] = None,
        limit: Optional[int] = None,
        offset: Optional[int] = None,
    ) -> Dict[str, Any]:
        """
        Make a paginated GET request to the Dependency Track API.

        Args:
            endpoint: API endpoint (without base URL)
            params: Query parameters
            limit: Maximum number of items to return
            offset: Number of items to skip

        Returns:
            Response data with pagination metadata
        """
        paginated_params = params.copy() if params else {}

        if limit is not None:
            paginated_params["limit"] = limit
        if offset is not None:
            paginated_params["offset"] = offset

        return self._make_request("GET", endpoint, params=paginated_params)

    def health_check(self) -> Dict[str, Any]:
        """
        Check the health status of the Dependency Track server.

        Uses the dedicated readiness endpoint which will indicate DT as DOWN
        if the database is down, unlike /version which will still respond.

        Returns:
            Server health information
        """
        # Use the readiness endpoint for proper health checking
        # Note: Health endpoints are on the root path, not under /api
        try:
            response = self._make_request("GET", "/health/ready")
            return {"status": "healthy", "details": response}
        except DependencyTrackAPIError:
            # If readiness check fails, try the basic health endpoint
            try:
                response = self._make_request("GET", "/health")
                return {"status": "degraded", "details": response}
            except DependencyTrackAPIError:
                # If both fail, the server is unhealthy
                return {"status": "unhealthy", "error": "Service unavailable"}

    def get_version(self) -> Dict[str, Any]:
        """
        Get the version information of the Dependency Track server.

        Note: /version will still respond if the database is down, while
        the readiness check will indicate DT as DOWN.

        Returns:
            Server version information
        """
        return self._make_request("GET", "/version")

    def create_project(
        self, name: str, version: str = "1.0.0", description: Optional[str] = None, tags: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        Create a new project in Dependency Track.

        Args:
            name: Project name
            version: Project version
            description: Project description
            tags: Project tags

        Returns:
            Created project data including UUID
        """
        project_data = {
            "name": name,
            "version": version,
            "classifier": "APPLICATION",  # Default classifier
        }

        if description:
            project_data["description"] = description

        if tags:
            project_data["tags"] = tags

        return self._make_request("PUT", "/v1/project", data=project_data)

    def get_project(self, project_uuid: str) -> Dict[str, Any]:
        """
        Get project details by UUID.

        Args:
            project_uuid: UUID of the project

        Returns:
            Project data
        """
        return self._make_request("GET", f"/v1/project/{project_uuid}")

    def update_project(
        self,
        project_uuid: str,
        name: Optional[str] = None,
        version: Optional[str] = None,
        description: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Update an existing project.

        Args:
            project_uuid: UUID of the project to update
            name: New project name
            version: New project version
            description: New project description

        Returns:
            Updated project data
        """
        # Get current project data first
        current_project = self.get_project(project_uuid)

        # Update only provided fields
        if name is not None:
            current_project["name"] = name
        if version is not None:
            current_project["version"] = version
        if description is not None:
            current_project["description"] = description

        return self._make_request("POST", "/v1/project", data=current_project)

    def upload_sbom(self, project_uuid: str, sbom_data: bytes, auto_create: bool = True) -> Dict[str, Any]:
        """
        Upload an SBOM to a project.

        CRITICAL: Dependency Track ONLY supports CycloneDX format, NOT SPDX!
        This method should only be called with CycloneDX SBOMs.

        Args:
            project_uuid: UUID of the target project
            sbom_data: SBOM file content as bytes (MUST be CycloneDX format)
            auto_create: Whether to auto-create components

        Returns:
            Upload response data

        Raises:
            DependencyTrackAPIError: If SBOM is not CycloneDX format or upload fails
        """
        # Validate that SBOM is CycloneDX format - DT does NOT support SPDX!
        try:
            content = json.loads(sbom_data.decode("utf-8"))
            if content.get("bomFormat") != "CycloneDX":
                if content.get("spdxVersion"):
                    raise DependencyTrackAPIError(
                        "SPDX format is not supported by Dependency Track. Only CycloneDX format is supported."
                    )
                else:
                    raise DependencyTrackAPIError(
                        "Invalid SBOM format. Dependency Track only supports CycloneDX format."
                    )
        except json.JSONDecodeError:
            raise DependencyTrackAPIError("Invalid SBOM: Content is not valid JSON")

        # Prepare the upload data
        upload_data = {"project": project_uuid, "autoCreate": str(auto_create).lower()}

        files = {"bom": ("sbom.json", sbom_data, "application/json")}

        return self._make_request("POST", "/v1/bom", data=upload_data, files=files)

    def upload_sbom_with_project_creation(
        self, project_name: str, project_version: str, sbom_data: bytes, auto_create: bool = True
    ) -> Dict[str, Any]:
        """
        Upload an SBOM and create a project in a single operation.

        This is the WORKING method for DT instances that restrict direct project creation
        but allow project creation via BOM upload with autoCreate=true.

        CRITICAL: Dependency Track ONLY supports CycloneDX format, NOT SPDX!

        Args:
            project_name: Name for the project to create
            project_version: Version for the project to create
            sbom_data: SBOM file content as bytes (MUST be CycloneDX format)
            auto_create: Whether to auto-create the project and components

        Returns:
            Upload response data including processing token

        Raises:
            DependencyTrackAPIError: If SBOM is not CycloneDX format or upload fails
        """
        # Validate that SBOM is CycloneDX format - DT does NOT support SPDX!
        try:
            content = json.loads(sbom_data.decode("utf-8"))
            if content.get("bomFormat") != "CycloneDX":
                if content.get("spdxVersion"):
                    raise DependencyTrackAPIError(
                        "SPDX format is not supported by Dependency Track. Only CycloneDX format is supported."
                    )
                else:
                    raise DependencyTrackAPIError(
                        "Invalid SBOM format. Dependency Track only supports CycloneDX format."
                    )
        except json.JSONDecodeError:
            raise DependencyTrackAPIError("Invalid SBOM: Content is not valid JSON")

        # Prepare the upload data for project creation
        upload_data = {
            "projectName": project_name,
            "projectVersion": project_version,
            "autoCreate": str(auto_create).lower(),
        }

        files = {"bom": ("sbom.json", sbom_data, "application/json")}

        return self._make_request("POST", "/v1/bom", data=upload_data, files=files)

    def find_project_by_name_version(self, project_name: str, project_version: str) -> Optional[Dict[str, Any]]:
        """
        Find a project by name and version using the optimized lookup endpoint.

        This is used after BOM-based project creation to locate the created project.

        Args:
            project_name: Name of the project to find
            project_version: Version of the project to find

        Returns:
            Project data if found, None otherwise
        """
        try:
            # Use the optimized lookup endpoint instead of getting all projects
            params = {"name": project_name, "version": project_version}
            response = self._make_request("GET", "/v1/project/lookup", params=params)

            # The lookup endpoint returns the project directly or 404 if not found
            return response

        except DependencyTrackAPIError as e:
            # Return None if project not found (404) or other API errors
            if e.status_code == 404:
                return None
            return None

    def get_project_metrics(self, project_uuid: str) -> Dict[str, Any]:
        """
        Get vulnerability metrics for a project.

        Args:
            project_uuid: UUID of the project

        Returns:
            Project metrics including vulnerability counts
        """
        return self._make_request("GET", f"/v1/metrics/project/{project_uuid}/current")

    def get_project_vulnerabilities(
        self, project_uuid: str, suppressed: bool = False, limit: Optional[int] = None, offset: Optional[int] = None
    ) -> Dict[str, Any]:
        """
        Get vulnerabilities for a project using the optimized finding endpoint.

        Args:
            project_uuid: UUID of the project
            suppressed: Include suppressed vulnerabilities
            limit: Maximum number of vulnerabilities to return (for pagination)
            offset: Number of vulnerabilities to skip (for pagination)

        Returns:
            Dictionary containing vulnerabilities list and pagination metadata
        """
        params = {"suppressed": str(suppressed).lower()}
        response = self._make_paginated_request(f"/v1/finding/project/{project_uuid}", params, limit, offset)

        # v1 API always returns an array for collection resources
        # The total number of items is indicated via the X-Total-Count response header
        if isinstance(response, dict) and "content" in response:
            # Paginated response with metadata
            return response
        elif isinstance(response, list):
            # Direct list response (no pagination metadata)
            return {"content": response, "totalElements": len(response), "paginated": False}
        else:
            return {"content": [], "totalElements": 0, "paginated": False}

    def get_project_components(self, project_uuid: str) -> List[Dict[str, Any]]:
        """
        Get all components for a project.

        Args:
            project_uuid: UUID of the project

        Returns:
            List of components
        """
        response = self._make_request("GET", f"/v1/component/project/{project_uuid}")

        # Handle paginated response
        if isinstance(response, list):
            return response
        elif isinstance(response, dict) and "content" in response:
            return response["content"]
        else:
            return []

    def delete_project(self, project_uuid: str) -> None:
        """
        Delete a project.

        Args:
            project_uuid: UUID of the project to delete
        """
        self._make_request("DELETE", f"/v1/project/{project_uuid}")

    def get_analysis(
        self, component_uuid: str, vulnerability_uuid: str, project_uuid: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Get vulnerability analysis for a component.

        Args:
            component_uuid: UUID of the component
            vulnerability_uuid: UUID of the vulnerability
            project_uuid: UUID of the project (optional)

        Returns:
            Analysis data
        """
        params = {"component": component_uuid, "vulnerability": vulnerability_uuid}
        if project_uuid:
            params["project"] = project_uuid

        return self._make_request("GET", "/v1/analysis", params=params)
