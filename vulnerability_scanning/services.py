"""Service layer for vulnerability scanning integration."""

import logging
from datetime import timedelta
from typing import Any, Dict, List, Optional

from django.conf import settings
from django.db import models, transaction
from django.utils import timezone

from .clients import DependencyTrackAPIError, DependencyTrackClient, OSVClient, VulnerabilityProviderError
from .models import (
    ComponentDependencyTrackMapping,
    DependencyTrackServer,
    TeamVulnerabilitySettings,
    VulnerabilityScanResult,
)

logger = logging.getLogger(__name__)


class StandardizedVulnerabilityData:
    """
    Standardized vulnerability data structure for consistent storage across providers.

    Both OSV and Dependency Track results are normalized to this format.
    """

    @staticmethod
    def normalize_vulnerability(vuln_data: Dict[str, Any], provider: str) -> Dict[str, Any]:
        """
        Normalize a single vulnerability to standard format.

        Args:
            vuln_data: Raw vulnerability data from provider
            provider: Provider name ('osv' or 'dependency_track')

        Returns:
            Standardized vulnerability dictionary
        """
        if provider == "osv":
            return {
                "id": vuln_data.get("id", "unknown"),
                "source": "OSV",
                "severity": vuln_data.get("severity", "unknown"),
                "title": vuln_data.get("summary", vuln_data.get("title", "")),
                "description": vuln_data.get("details", vuln_data.get("description", "")),
                "references": [
                    ref.get("url") if isinstance(ref, dict) else ref for ref in vuln_data.get("references", []) if ref
                ],
                "aliases": vuln_data.get("aliases", []),
                "cvss_score": StandardizedVulnerabilityData._extract_cvss_score(vuln_data),
                "component": {
                    "name": vuln_data.get("package_name") or vuln_data.get("component", {}).get("name", "unknown"),
                    "version": vuln_data.get("component", {}).get("version", "unknown"),
                    "ecosystem": vuln_data.get("component", {}).get("ecosystem", "unknown"),
                    "purl": vuln_data.get("component", {}).get("purl", ""),
                },
                "affected": vuln_data.get("affected", []),
                "published_at": vuln_data.get("published"),
                "modified_at": vuln_data.get("modified"),
                "provider_specific": {
                    "database_specific": vuln_data.get("database_specific", {}),
                    "ecosystem_specific": vuln_data.get("ecosystem_specific", {}),
                },
            }

        elif provider == "dependency_track":
            return {
                "id": vuln_data.get("vulnId", vuln_data.get("id", "unknown")),
                "source": vuln_data.get("source", "Dependency Track"),
                "severity": vuln_data.get("severity", "unknown").lower(),
                "title": vuln_data.get("title", ""),
                "description": vuln_data.get("description", ""),
                "references": vuln_data.get("references", []),
                "aliases": vuln_data.get("aliases", []),
                "cvss_score": (
                    vuln_data.get("cvssV3BaseScore") or vuln_data.get("cvssV2BaseScore") or vuln_data.get("cvss_score")
                ),
                "component": {
                    "name": vuln_data.get("component", {}).get("name", "unknown"),
                    "version": vuln_data.get("component", {}).get("version", "unknown"),
                    "ecosystem": "unknown",  # DT doesn't always provide this
                    "purl": vuln_data.get("component", {}).get("purl", ""),
                },
                "affected": vuln_data.get("affected", []),
                "published_at": vuln_data.get("published"),
                "modified_at": vuln_data.get("modified"),
                "provider_specific": {
                    "recommendation": vuln_data.get("recommendation", ""),
                    "cwes": vuln_data.get("cwes", []),
                    "cvssV3Vector": vuln_data.get("cvssV3Vector", ""),
                    "cvssV2Vector": vuln_data.get("cvssV2Vector", ""),
                },
            }

        else:
            raise ValueError(f"Unknown provider: {provider}")

    @staticmethod
    def _extract_cvss_score(vuln_data: Dict[str, Any]) -> Optional[float]:
        """Extract CVSS score from vulnerability data."""
        # Check for direct cvss_score field
        if "cvss_score" in vuln_data and isinstance(vuln_data["cvss_score"], (int, float)):
            return float(vuln_data["cvss_score"])

        # Handle case where severity is already processed (e.g., from OSV client)
        severity = vuln_data.get("severity")
        if isinstance(severity, str):
            # Already processed by client, no CVSS score available
            return None

        # Parse from severity array (raw OSV format)
        if isinstance(severity, list):
            for severity_item in severity:
                if isinstance(severity_item, dict) and severity_item.get("type") == "CVSS_V3":
                    try:
                        # Extract numeric score from CVSS string if available
                        score_str = severity_item.get("score", "")
                        if "/" in score_str:
                            # Format like "9.8/CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H"
                            score_part = score_str.split("/")[0]
                            return float(score_part)
                    except (ValueError, TypeError):
                        continue

        return None

    @staticmethod
    def normalize_scan_results(
        raw_results: Dict[str, Any], provider: str, scan_trigger: str = "upload"
    ) -> Dict[str, Any]:
        """
        Normalize complete scan results to standardized format.

        Args:
            raw_results: Raw results from provider
            provider: Provider name
            scan_trigger: How the scan was triggered

        Returns:
            Standardized scan results
        """
        # Standardize vulnerability count format
        vuln_count = raw_results.get("vulnerability_count", {})
        if not isinstance(vuln_count, dict):
            vuln_count = {"total": 0, "critical": 0, "high": 0, "medium": 0, "low": 0, "info": 0, "unknown": 0}

        # Ensure all required severity levels exist
        standardized_count = {
            "total": vuln_count.get("total", 0),
            "critical": vuln_count.get("critical", 0),
            "high": vuln_count.get("high", 0),
            "medium": vuln_count.get("medium", 0),
            "low": vuln_count.get("low", 0),
            "info": vuln_count.get("info", 0),
            "unknown": vuln_count.get("unknown", 0),
        }

        # Normalize findings format
        findings = []
        raw_findings = raw_results.get("findings", [])

        if provider == "osv":
            # OSV format: {"vulnerabilities": [...]} or direct list
            if isinstance(raw_findings, dict) and "vulnerabilities" in raw_findings:
                raw_vulns = raw_findings["vulnerabilities"]
            else:
                raw_vulns = raw_findings if isinstance(raw_findings, list) else []
        else:
            # DT format: direct list
            raw_vulns = raw_findings if isinstance(raw_findings, list) else []

        # Normalize each vulnerability
        for vuln in raw_vulns:
            try:
                # Skip if vuln is not a dictionary
                if not isinstance(vuln, dict):
                    logger.warning(f"Skipping non-dictionary vulnerability data: {type(vuln)}")
                    continue

                normalized_vuln = StandardizedVulnerabilityData.normalize_vulnerability(vuln, provider)
                findings.append(normalized_vuln)
            except Exception as e:
                vuln_id = vuln.get("id", "unknown") if isinstance(vuln, dict) else "unknown"
                logger.warning(f"Failed to normalize vulnerability {vuln_id}: {e}")
                continue

        # Extract provider-specific metadata
        scan_metadata = {}
        if provider == "osv":
            scan_metadata = {
                "raw_output": raw_results.get("raw_output", ""),
                "scan_summary": raw_results.get("scan_summary", ""),
                "parse_error": raw_results.get("parse_error", ""),
            }
        elif provider == "dependency_track":
            scan_metadata = raw_results.get("metrics", {})

        return {
            "provider": provider,
            "scan_trigger": scan_trigger,
            "vulnerability_count": standardized_count,
            "findings": findings,  # Direct list format for both providers
            "scan_metadata": scan_metadata,
            "scan_timestamp": raw_results.get("scan_timestamp", timezone.now().isoformat()),
            "cached": raw_results.get("cached", False),
        }


class VulnerabilityScanningService:
    """
    Service for managing vulnerability scanning across different providers.

    Handles provider selection, component mapping, and result caching with standardized storage.
    """

    def __init__(self):
        self.cache_ttl = getattr(settings, "VULNERABILITY_SCAN_CACHE_TTL", 3600)  # 1 hour default
        self.osv_client = OSVClient()

    def _get_environment_prefix(self) -> str:
        """
        Generate an environment prefix based on APP_BASE_URL for DT project naming.

        This helps differentiate projects between environments (dev, staging, prod)
        when using a shared Dependency Track instance.

        You can override the automatic detection by setting the DT_ENVIRONMENT_PREFIX
        environment variable.

        Examples:
        - https://app.sbomify.com -> "prod"
        - https://staging.sbomify.com -> "staging"
        - https://dev.sbomify.com -> "dev"
        - http://localhost:8000 -> "local"
        - DT_ENVIRONMENT_PREFIX="custom" -> "custom"

        Returns:
            Environment prefix string
        """
        import os
        from urllib.parse import urlparse

        from django.conf import settings

        try:
            # Check for explicit override first
            override_prefix = os.environ.get("DT_ENVIRONMENT_PREFIX", "").strip()
            if override_prefix:
                logger.info(f"Using explicit DT environment prefix: {override_prefix}")
                return override_prefix

            app_base_url = getattr(settings, "APP_BASE_URL", "")

            if not app_base_url:
                return "unknown"

            parsed = urlparse(app_base_url)
            hostname = parsed.hostname

            # Handle cases where hostname is None (invalid URLs)
            if not hostname:
                # Try to extract from netloc as fallback
                netloc_parts = parsed.netloc.split(":")
                if netloc_parts and netloc_parts[0]:
                    hostname = netloc_parts[0]
                else:
                    return "unknown"

            # Handle localhost/development
            if hostname in ["localhost", "127.0.0.1", "0.0.0.0"]:  # nosec B104
                return "local"

            # Extract environment from subdomain or domain (prioritize keyword matching)
            hostname_lower = hostname.lower()
            if "staging" in hostname_lower:
                return "staging"
            elif "dev" in hostname_lower or "development" in hostname_lower:
                return "dev"
            elif "test" in hostname_lower:
                return "test"
            elif "prod" in hostname_lower:
                return "prod"
            else:
                # For main domains like app.sbomify.com, sbomify.com - consider production
                if hostname_lower.endswith(".com") or hostname_lower.endswith(".org"):
                    # Check if it's a main domain or if we should use the subdomain
                    parts = hostname_lower.split(".")
                    if len(parts) >= 3:  # subdomain.domain.com
                        # Use the first part as environment if it's not a common app prefix
                        first_part = parts[0]
                        if first_part not in ["app", "www", "api"]:
                            return first_part
                    return "prod"
                else:
                    # Use the first part of the hostname as environment identifier
                    parts = hostname_lower.split(".")
                    return parts[0] if parts and parts[0] else "unknown"

        except Exception as e:
            logger.warning(f"Failed to determine environment prefix from APP_BASE_URL: {e}")
            return "unknown"

    def scan_sbom_for_vulnerabilities(self, sbom, sbom_data: bytes, scan_trigger: str = "upload") -> Dict[str, Any]:
        """
        Main entry point for vulnerability scanning.

        Determines the appropriate provider based on team settings and routes the scan.

        Args:
            sbom: SBOM instance
            sbom_data: SBOM file content as bytes
            scan_trigger: How the scan was triggered ("upload", "manual", "weekly", "api")

        Returns:
            Standardized scan results dictionary
        """
        try:
            team = sbom.component.team

            # Determine which provider to use
            if self.should_use_dependency_track(team, sbom_data):
                logger.info(f"Using Dependency Track for SBOM {sbom.id} (team: {team.key})")
                raw_results = self._scan_with_dependency_track(sbom, sbom_data)
                provider = "dependency_track"
            else:
                logger.info(f"Using OSV for SBOM {sbom.id} (team: {team.key})")
                raw_results = self._scan_with_osv(sbom, sbom_data)
                provider = "osv"

            # Standardize the results
            standardized_results = StandardizedVulnerabilityData.normalize_scan_results(
                raw_results, provider, scan_trigger
            )

            # Add SBOM metadata
            standardized_results.update({"sbom_id": str(sbom.id), "scan_timestamp": timezone.now().isoformat()})

            return standardized_results

        except Exception as e:
            logger.error(f"Vulnerability scan failed for SBOM {sbom.id}: {e}")

            # Preserve additional error data from VulnerabilityProviderError
            error_data = {"error": f"Vulnerability scan failed: {str(e)}", "vulnerability_count": {}, "findings": []}
            provider = "unknown"

            if isinstance(e, VulnerabilityProviderError) and hasattr(e, "response_data") and e.response_data:
                error_data.update(e.response_data)
                provider = e.response_data.get("provider", "unknown")

            return StandardizedVulnerabilityData.normalize_scan_results(error_data, provider, scan_trigger)

    def store_scan_results(
        self, sbom, standardized_results: Dict[str, Any], component_mapping: ComponentDependencyTrackMapping = None
    ) -> VulnerabilityScanResult:
        """
        Store standardized scan results in PostgreSQL.

        Args:
            sbom: SBOM instance
            standardized_results: Normalized scan results
            component_mapping: DT mapping if applicable

        Returns:
            Created VulnerabilityScanResult instance
        """
        # Create new result (keep all historical data)
        result = VulnerabilityScanResult.objects.create(
            sbom=sbom,
            provider=standardized_results["provider"],
            scan_trigger=standardized_results["scan_trigger"],
            component_mapping=component_mapping,
            vulnerability_count=standardized_results["vulnerability_count"],
            findings=standardized_results["findings"],
            scan_metadata=standardized_results["scan_metadata"],
        )

        logger.info(f"Stored standardized {standardized_results['provider']} results for SBOM {sbom.id}")
        return result

    def get_cached_results(self, sbom, provider: str = None) -> Optional[Dict[str, Any]]:
        """Get latest scan results from PostgreSQL (no expiration concept)."""
        try:
            result = VulnerabilityScanResult.get_latest_for_sbom(sbom, provider)

            if result:
                return {
                    "vulnerability_count": result.vulnerability_count,
                    "findings": result.findings,
                    "scan_metadata": result.scan_metadata,
                    "provider": result.provider,
                    "scan_trigger": result.scan_trigger,
                    "cached": False,  # No longer caching, just historical data
                    "sbom_id": str(sbom.id),
                    "scan_timestamp": result.created_at.isoformat(),
                }
        except Exception as e:
            logger.warning(f"Failed to get latest results for SBOM {sbom.id}: {e}")

        return None

    def should_use_dependency_track(self, team, sbom_data: bytes = None) -> bool:
        """
        Determine if Dependency Track should be used for this team and SBOM.

        CRITICAL: Dependency Track ONLY supports CycloneDX format, NOT SPDX!
        SPDX SBOMs must always use OSV regardless of team plan.

        Args:
            team: Team instance
            sbom_data: Optional SBOM content for format validation

        Returns:
            True if DT should be used, False for OSV
        """
        # Check if team has Business/Enterprise plan
        if not team.billing_plan or team.billing_plan not in ["business", "enterprise"]:
            return False

        # Get team settings
        team_settings = self.get_or_create_team_settings(team)

        # Check if team has explicitly chosen Dependency Track
        if team_settings.vulnerability_provider != "dependency_track":
            return False

        # CRITICAL: Check SBOM format - DT only supports CycloneDX
        if sbom_data:
            # Use proper format detection (content-based only)
            format_type = self.osv_client.detect_sbom_format(sbom_data)

            if format_type == "spdx":
                logger.warning(
                    f"Team {team.key} configured for Dependency Track but SBOM is SPDX format. "
                    f"Forcing OSV usage as DT only supports CycloneDX."
                )
                return False

            elif format_type == "cyclonedx":
                logger.debug(f"SBOM is CycloneDX format, compatible with Dependency Track for team {team.key}")
                return True

            else:  # unknown format
                logger.warning(
                    f"Team {team.key} configured for Dependency Track but SBOM format is unknown. "
                    f"Forcing OSV usage as DT only supports CycloneDX."
                )
                return False

        return True

    def get_or_create_team_settings(self, team) -> TeamVulnerabilitySettings:
        """Get or create team vulnerability settings."""
        settings, created = TeamVulnerabilitySettings.objects.get_or_create(
            team=team, defaults={"vulnerability_provider": "osv"}
        )

        if created:
            logger.info(f"Created default vulnerability settings for team {team.key}")

        return settings

    def _scan_with_osv(self, sbom, sbom_data: bytes) -> Dict[str, Any]:
        """Scan SBOM using OSV scanner."""
        try:
            # Check for recent results first (avoid duplicate scans)
            cached_result = self._get_cached_osv_results(sbom)
            if cached_result:
                return cached_result

            # Perform OSV scan
            scan_results = self.osv_client.scan_sbom(sbom_data, sbom.sbom_filename)

            # Add metadata
            scan_results.update(
                {
                    "sbom_id": str(sbom.id),
                    "scan_timestamp": timezone.now().isoformat(),
                    "cached": False,
                    "provider": "osv",
                }
            )

            # Store results in PostgreSQL
            self._cache_osv_results(sbom, scan_results)

            return scan_results

        except VulnerabilityProviderError as e:
            logger.error(f"OSV scan failed for SBOM {sbom.id}: {e}")
            error_result = {"error": str(e), "sbom_id": str(sbom.id), "provider": "osv"}

            # Include additional error data if available
            if hasattr(e, "response_data") and e.response_data:
                error_result.update(e.response_data)

            return error_result

    def _scan_with_dependency_track(self, sbom, sbom_data: bytes) -> Dict[str, Any]:
        """Scan SBOM using Dependency Track with intelligent upload/polling logic."""
        try:
            team = sbom.component.team

            # Select DT server
            dt_server = self.select_dependency_track_server(team)

            # Check if we have an existing mapping and recent upload
            mapping = self.get_or_create_component_mapping(sbom.component, dt_server)

            # Determine if we should upload or just poll for updates
            should_upload = self._should_upload_to_dt(sbom, mapping)

            if should_upload:
                logger.info(f"Uploading SBOM {sbom.id} to DT (new or outdated)")
                # Upload SBOM to DT (creates project if mapping is None)
                upload_result = self.upload_sbom_to_dependency_track(sbom, sbom_data, mapping)
                final_mapping = upload_result["mapping"]
                created_project = upload_result.get("created_project", False)

                if not final_mapping:
                    logger.error(f"No mapping available after DT upload for SBOM {sbom.id}")
                    return {
                        "error": "No project mapping available after upload",
                        "sbom_id": str(sbom.id),
                        "provider": "dependency_track",
                    }

                # Queue polling task for new upload
                from .tasks import poll_dependency_track_results_task

                poll_dependency_track_results_task.send(
                    str(sbom.id), str(final_mapping.id), max_attempts=6, initial_delay=30
                )

                # Return processing state
                return {
                    "status": "processing",
                    "provider": "dependency_track",
                    "sbom_id": str(sbom.id),
                    "dt_server": dt_server.name,
                    "dt_project_uuid": str(final_mapping.dt_project_uuid),
                    "created_project": created_project,
                    "scan_timestamp": timezone.now().isoformat(),
                    "message": "SBOM uploaded to Dependency Track. Processing vulnerability data...",
                    "action": "upload",
                    "vulnerability_count": {"critical": 0, "high": 0, "medium": 0, "low": 0, "info": 0, "total": 0},
                    "findings": [],
                    "scan_metadata": {"processing": True, "expected_completion": "2-5 minutes", "action": "upload"},
                }
            else:
                logger.info(f"Polling for updated vulnerability data for SBOM {sbom.id} (recent upload)")
                # Just poll for updated vulnerability data
                try:
                    scan_results = self.get_dependency_track_results(sbom, mapping, force_refresh=True)

                    # Update the last sync timestamp
                    mapping.last_metrics_sync = timezone.now()
                    mapping.save(update_fields=["last_metrics_sync"])

                    # Add metadata
                    scan_results.update(
                        {
                            "sbom_id": str(sbom.id),
                            "scan_timestamp": timezone.now().isoformat(),
                            "cached": False,
                            "dt_server": dt_server.name,
                            "dt_project_uuid": str(mapping.dt_project_uuid),
                            "action": "poll",
                        }
                    )

                    logger.info(f"Successfully polled updated vulnerabilities for SBOM {sbom.id}")
                    return scan_results

                except Exception as poll_error:
                    logger.warning(f"Failed to poll DT updates for SBOM {sbom.id}: {poll_error}")
                    # Fall back to cached results if polling fails
                    cached_result = self._get_cached_dt_results(sbom, mapping)
                    if cached_result:
                        cached_result.update({"action": "poll_failed_cached", "poll_error": str(poll_error)})
                        return cached_result
                    else:
                        # No cached results, return error
                        return {
                            "error": f"Failed to poll DT updates and no cached results: {poll_error}",
                            "sbom_id": str(sbom.id),
                            "provider": "dependency_track",
                            "action": "poll_failed",
                        }

        except VulnerabilityProviderError as e:
            logger.error(f"Dependency Track scan failed for SBOM {sbom.id}: {e}")
            return {"error": "Service error", "sbom_id": str(sbom.id), "provider": "dependency_track"}

    def _should_upload_to_dt(self, sbom, mapping: Optional[ComponentDependencyTrackMapping]) -> bool:
        """
        Determine if we should upload SBOM to DT or just poll for updated vulnerability data.

        Logic:
        - No mapping exists → Upload (first time)
        - Mapping exists but no SBOM uploaded recently → Upload
        - Mapping exists with recent upload (< 24h) → Poll only
        - Mapping exists but old upload (> 24h) → Upload (refresh)

        Args:
            sbom: SBOM instance
            mapping: Existing ComponentDependencyTrackMapping or None

        Returns:
            True if should upload, False if should poll only
        """

        # No mapping = first time, must upload
        if not mapping:
            logger.debug(f"No DT mapping for SBOM {sbom.id}, will upload")
            return True

        # Check if this specific SBOM has been uploaded recently
        recent_threshold = timezone.now() - timedelta(hours=24)

        # Check if we have any recent scan results for this specific SBOM
        recent_dt_scan = (
            VulnerabilityScanResult.objects.filter(
                sbom=sbom, provider="dependency_track", component_mapping=mapping, created_at__gte=recent_threshold
            )
            .order_by("-created_at")
            .first()
        )

        if recent_dt_scan:
            # Check if it was an upload action (not just a poll)
            scan_metadata = recent_dt_scan.scan_metadata or {}
            last_action = scan_metadata.get("action", "unknown")

            if last_action in ["upload", "poll"]:
                logger.debug(f"SBOM {sbom.id} has recent DT scan ({last_action}), will poll for updates")
                return False

        # Check mapping's last upload timestamp
        if mapping.last_sbom_upload:
            time_since_upload = timezone.now() - mapping.last_sbom_upload

            if time_since_upload < timedelta(hours=24):
                logger.debug(f"Component mapping has recent upload ({time_since_upload}), will poll for updates")
                return False
            else:
                logger.debug(f"Component mapping upload is old ({time_since_upload}), will refresh with upload")
                return True

        # Mapping exists but no upload timestamp = upload
        logger.debug(f"Mapping exists but no upload timestamp for SBOM {sbom.id}, will upload")
        return True

    def get_team_vulnerability_provider(self, team) -> str:
        """
        Get the vulnerability scanning provider for a team.

        Args:
            team: Team instance

        Returns:
            Provider name ('osv' or 'dependency_track')
        """
        try:
            settings_obj = TeamVulnerabilitySettings.objects.get(team=team)
            return settings_obj.vulnerability_provider
        except TeamVulnerabilitySettings.DoesNotExist:
            # Default to OSV if no settings exist
            return "osv"

    def select_dependency_track_server(self, team) -> DependencyTrackServer:
        """
        Select a Dependency Track server for a team.

        - Enterprise teams: Can use custom server OR shared pool
        - Business teams: Can only use shared pool
        - Uses round-robin selection from available servers in the pool
        - Performs just-in-time health checks if no healthy servers are available

        Args:
            team: Team instance

        Returns:
            DependencyTrackServer instance

        Raises:
            VulnerabilityProviderError: If no suitable server is available
        """
        # Check for custom DT server (Enterprise only)
        if team.billing_plan == "enterprise":
            try:
                team_settings = TeamVulnerabilitySettings.objects.get(team=team)
                if team_settings.custom_dt_server and team_settings.custom_dt_server.is_available_for_scan:
                    return team_settings.custom_dt_server
            except TeamVulnerabilitySettings.DoesNotExist:
                pass

        # Use server pool with round-robin selection
        available_servers = (
            DependencyTrackServer.objects.filter(is_active=True, health_status__in=["healthy", "degraded"])
            .exclude(current_scan_count__gte=models.F("max_concurrent_scans"))
            .order_by("priority", "current_scan_count")
        )

        if available_servers.exists():
            # Select server with lowest load in highest priority group
            selected_server = available_servers.first()

            # Increment scan count atomically
            DependencyTrackServer.objects.filter(id=selected_server.id).update(
                current_scan_count=models.F("current_scan_count") + 1
            )

            return selected_server

        # No healthy servers found - try just-in-time health checks
        logger.warning("No healthy DT servers found, attempting just-in-time health checks")

        # Get all active servers regardless of health status, but still respect capacity limits
        candidate_servers = (
            DependencyTrackServer.objects.filter(is_active=True)
            .exclude(current_scan_count__gte=models.F("max_concurrent_scans"))
            .order_by("priority", "current_scan_count")
        )

        for server in candidate_servers:
            try:
                # Perform quick health check
                logger.info(f"Performing just-in-time health check for DT server: {server.name}")
                health_result = self.check_dependency_track_server_health(server)

                if health_result["status"] in ["healthy", "degraded"]:
                    # Server is available, increment scan count and return
                    DependencyTrackServer.objects.filter(id=server.id).update(
                        current_scan_count=models.F("current_scan_count") + 1
                    )
                    logger.info(f"Successfully validated DT server {server.name} via just-in-time health check")
                    return server
                else:
                    error_msg = health_result.get("error", "Unknown error")
                    logger.warning(f"DT server {server.name} failed just-in-time health check: {error_msg}")

            except Exception as e:
                logger.warning(f"Just-in-time health check failed for DT server {server.name}: {e}")
                continue

        # If we get here, no servers are available
        raise VulnerabilityProviderError("No available Dependency Track servers")

    def get_or_create_component_mapping(
        self, component, dt_server: DependencyTrackServer
    ) -> ComponentDependencyTrackMapping:
        """
        Get or create a mapping between sbomify component and DT project.

        Note: This method now returns None for new mappings since project creation
        happens during the first SBOM upload. The mapping is created after successful
        BOM-based project creation.

        Args:
            component: Component instance
            dt_server: DependencyTrackServer instance

        Returns:
            ComponentDependencyTrackMapping instance if existing, None if needs to be created
        """
        # Check for existing mapping
        try:
            mapping = ComponentDependencyTrackMapping.objects.get(component=component, dt_server=dt_server)
            return mapping
        except ComponentDependencyTrackMapping.DoesNotExist:
            # Return None to indicate that project creation will happen via BOM upload
            # The mapping will be created after successful BOM-based project creation
            logger.info(
                f"No existing DT project mapping for component {component.id} on server {dt_server.name}. "
                f"Project will be created via BOM upload."
            )
            return None

    def create_component_mapping_after_bom_upload(
        self, component, dt_server: DependencyTrackServer, project_name: str, project_version: str
    ) -> Optional[ComponentDependencyTrackMapping]:
        """
        Create a component mapping after successful BOM-based project creation.

        Args:
            component: Component instance
            dt_server: DependencyTrackServer instance
            project_name: Name of the created project
            project_version: Version of the created project

        Returns:
            ComponentDependencyTrackMapping instance if project found, None otherwise
        """
        try:
            # Create DT client
            client = DependencyTrackClient(dt_server.url, dt_server.api_key)

            # Find the created project
            project_data = client.find_project_by_name_version(project_name, project_version)

            if not project_data:
                logger.error(
                    f"Could not find DT project {project_name} v{project_version} after BOM upload "
                    f"for component {component.id}"
                )
                return None

            # Create mapping record
            with transaction.atomic():
                mapping = ComponentDependencyTrackMapping.objects.create(
                    component=component,
                    dt_server=dt_server,
                    dt_project_uuid=project_data["uuid"],
                    dt_project_name=project_data["name"],
                )

                logger.info(
                    f"Created DT project mapping {project_data['uuid']} for component {component.id} "
                    f"on server {dt_server.name} after BOM upload"
                )

                return mapping

        except Exception as e:
            logger.error(f"Failed to create component mapping after BOM upload for component {component.id}: {e}")
            return None

    def upload_sbom_to_dependency_track(
        self, sbom, sbom_data: bytes, mapping: Optional[ComponentDependencyTrackMapping]
    ) -> Dict[str, Any]:
        """
        Upload an SBOM to Dependency Track.

        If mapping is None, creates a new project via BOM upload.
        If mapping exists, uploads to existing project.

        Args:
            sbom: SBOM instance
            sbom_data: SBOM file content as bytes
            mapping: ComponentDependencyTrackMapping instance or None for new projects

        Returns:
            Upload result and mapping info
        """
        component = sbom.component

        try:
            if mapping:
                # Upload to existing project
                client = DependencyTrackClient(mapping.dt_server.url, mapping.dt_server.api_key)

                upload_result = client.upload_sbom(
                    project_uuid=str(mapping.dt_project_uuid), sbom_data=sbom_data, auto_create=True
                )

                # Update mapping timestamp
                mapping.last_sbom_upload = timezone.now()
                mapping.save(update_fields=["last_sbom_upload"])

                logger.info(f"Uploaded SBOM {sbom.id} to existing DT project {mapping.dt_project_uuid}")

                return {"upload_result": upload_result, "mapping": mapping, "created_project": False}

            else:
                # Create new project via BOM upload
                dt_server = self.select_dependency_track_server(component.team)
                client = DependencyTrackClient(dt_server.url, dt_server.api_key)

                # Generate project name and version with environment prefix
                env_prefix = self._get_environment_prefix()
                project_name = f"{env_prefix}-sbomify-{component.id}"
                project_version = "1.0.0"

                # Upload SBOM with project creation
                upload_result = client.upload_sbom_with_project_creation(
                    project_name=project_name, project_version=project_version, sbom_data=sbom_data, auto_create=True
                )

                logger.info(f"Uploaded SBOM {sbom.id} with DT project creation: {project_name} v{project_version}")

                # Create mapping after successful upload
                new_mapping = self.create_component_mapping_after_bom_upload(
                    component=component, dt_server=dt_server, project_name=project_name, project_version=project_version
                )

                if new_mapping:
                    new_mapping.last_sbom_upload = timezone.now()
                    new_mapping.save(update_fields=["last_sbom_upload"])

                return {
                    "upload_result": upload_result,
                    "mapping": new_mapping,
                    "created_project": True,
                    "project_name": project_name,
                    "project_version": project_version,
                }

        except DependencyTrackAPIError as e:
            logger.error(f"Failed to upload SBOM {sbom.id} to DT: {e}")
            raise VulnerabilityProviderError(f"SBOM upload failed: {e}")

        finally:
            # Always decrement scan count for the appropriate server
            if mapping:
                server_id = mapping.dt_server.id
            else:
                # Get server again if we were creating new project
                try:
                    dt_server = self.select_dependency_track_server(component.team)
                    server_id = dt_server.id
                except Exception as e:
                    logger.warning(f"Failed to get DT server for cleanup: {e}")
                    server_id = None

            if server_id:
                DependencyTrackServer.objects.filter(id=server_id).update(
                    current_scan_count=models.F("current_scan_count") - 1
                )

    def get_dependency_track_results(
        self, sbom, mapping: ComponentDependencyTrackMapping, force_refresh: bool = False
    ) -> Dict[str, Any]:
        """
        Get vulnerability scan results from Dependency Track.

        Args:
            sbom: SBOM instance
            mapping: ComponentDependencyTrackMapping instance
            force_refresh: Force refresh from DT API

        Returns:
            Vulnerability scan results
        """
        # Check for recent results first (avoid duplicate scans)
        if not force_refresh:
            cached_result = self._get_cached_dt_results(sbom, mapping)
            if cached_result:
                return cached_result

        # Increment scan counter for this server
        if not mapping.dt_server.increment_scan_count():
            raise VulnerabilityProviderError(
                f"Dependency Track server {mapping.dt_server.name} is at capacity "
                f"({mapping.dt_server.current_scan_count}/{mapping.dt_server.max_concurrent_scans})"
            )

        try:
            client = DependencyTrackClient(mapping.dt_server.url, mapping.dt_server.api_key)

            # Get project metrics
            metrics = client.get_project_metrics(str(mapping.dt_project_uuid))

            # Get vulnerabilities (using the optimized finding endpoint)
            vulnerabilities_response = client.get_project_vulnerabilities(str(mapping.dt_project_uuid))

            # Extract the vulnerabilities list from the response
            vulnerabilities = vulnerabilities_response.get("content", [])

            # Debug logging to see what we're getting
            logger.info(
                f"DT API response for project {mapping.dt_project_uuid}: {len(vulnerabilities)} vulnerabilities"
            )
            if vulnerabilities:
                logger.info(f"First vulnerability structure keys: {list(vulnerabilities[0].keys())}")
                if "component" in vulnerabilities[0]:
                    comp = vulnerabilities[0]["component"]
                    logger.info(f"First component name: {comp.get('name', 'N/A')}")
                if "vulnerability" in vulnerabilities[0]:
                    vuln = vulnerabilities[0]["vulnerability"]
                    logger.info(f"First vulnerability ID: {vuln.get('vulnId', 'N/A')}")
            else:
                logger.warning(f"No vulnerabilities returned from DT for project {mapping.dt_project_uuid}")

            # Process and structure results
            results = self._process_dt_results(metrics, vulnerabilities)

            # Store results in PostgreSQL
            self._cache_dt_results(sbom, mapping, results)

            # Update mapping sync timestamp
            mapping.last_metrics_sync = timezone.now()
            mapping.save(update_fields=["last_metrics_sync"])

            return results

        except DependencyTrackAPIError as e:
            logger.error(f"Failed to get DT results for SBOM {sbom.id}: {e}")
            raise VulnerabilityProviderError(f"Failed to get DT results: {e}")

        finally:
            # Always decrement scan count
            mapping.dt_server.decrement_scan_count()

    def _get_cached_osv_results(self, sbom) -> Optional[Dict[str, Any]]:
        """Get recent OSV results (within last 24 hours)."""
        try:
            from datetime import timedelta

            # Check for recent results within 24 hours
            recent_threshold = timezone.now() - timedelta(hours=24)
            result = (
                VulnerabilityScanResult.objects.filter(sbom=sbom, provider="osv", created_at__gte=recent_threshold)
                .order_by("-created_at")
                .first()
            )

            if result:
                return {
                    "vulnerability_count": result.vulnerability_count,
                    "findings": result.findings,
                    "provider": "osv",
                    "cached": True,
                    "scan_date": result.created_at.isoformat(),
                    "sbom_id": str(sbom.id),
                }
        except Exception as e:
            logger.warning(f"Failed to get recent OSV results: {e}")

        return None

    def _cache_osv_results(self, sbom, results: Dict[str, Any]) -> None:
        """Store OSV results in standardized format."""
        try:
            # Standardize the results using our unified processor
            standardized_results = StandardizedVulnerabilityData.normalize_scan_results(results, "osv", "upload")

            # Store results (always create new record for historical tracking)
            VulnerabilityScanResult.objects.create(
                sbom=sbom,
                provider="osv",
                scan_trigger="upload",  # Default trigger
                vulnerability_count=standardized_results["vulnerability_count"],
                findings=standardized_results["findings"],
                scan_metadata=standardized_results["scan_metadata"],
                total_vulnerabilities=standardized_results["vulnerability_count"].get("total", 0),
                critical_vulnerabilities=standardized_results["vulnerability_count"].get("critical", 0),
                high_vulnerabilities=standardized_results["vulnerability_count"].get("high", 0),
                medium_vulnerabilities=standardized_results["vulnerability_count"].get("medium", 0),
                low_vulnerabilities=standardized_results["vulnerability_count"].get("low", 0),
                component_mapping=None,  # OSV doesn't use mappings
            )

        except Exception as e:
            logger.warning(f"Failed to store OSV results: {e}")

    def _get_cached_dt_results(self, sbom, mapping: ComponentDependencyTrackMapping = None) -> Optional[Dict[str, Any]]:
        """Get recent Dependency Track results (within last 24 hours)."""
        try:
            from datetime import timedelta

            # Check for recent results within 24 hours
            recent_threshold = timezone.now() - timedelta(hours=24)
            query_filter = {"sbom": sbom, "provider": "dependency_track", "created_at__gte": recent_threshold}

            if mapping:
                query_filter["component_mapping"] = mapping

            result = VulnerabilityScanResult.objects.filter(**query_filter).order_by("-created_at").first()

            if result:
                return {
                    "vulnerability_count": result.vulnerability_count,
                    "findings": result.findings,
                    "scan_metadata": result.scan_metadata,
                    "provider": "dependency_track",
                    "cached": True,
                    "scan_date": result.created_at.isoformat(),
                    "sbom_id": str(sbom.id),
                }
        except Exception as e:
            logger.warning(f"Failed to get recent DT results: {e}")

        return None

    def check_dependency_track_server_health(self, server: DependencyTrackServer) -> Dict[str, Any]:
        """
        Check the health of a Dependency Track server and update its status.

        Args:
            server: DependencyTrackServer instance to check

        Returns:
            Health check results
        """
        logger.info(f"Starting health check for DT server: {server.name}")

        try:
            client = DependencyTrackClient(server.url, server.api_key)

            # Perform health check
            health_result = client.health_check()

            # Determine status based on client response
            if health_result.get("status") == "degraded":
                server_status = "degraded"
            else:
                server_status = "healthy"

            # Update server status
            server.health_status = server_status
            server.last_health_check = timezone.now()
            server.save(update_fields=["health_status", "last_health_check"])

            logger.info(f"Health check successful for DT server: {server.name} (status: {server_status})")

            return {
                "server_id": str(server.id),
                "server_name": server.name,
                "status": server_status,
                "application": health_result.get("details", {}).get("application", "Unknown"),
                "version": health_result.get("details", {}).get("version", "Unknown"),
                "timestamp": health_result.get("details", {}).get("timestamp"),
                "message": "Health check successful",
            }

        except Exception as e:
            # Update server status to unhealthy
            server.health_status = "unhealthy"
            server.last_health_check = timezone.now()
            server.save(update_fields=["health_status", "last_health_check"])

            logger.error(f"Health check failed for DT server: {server.name}: {e}")

            return {
                "server_id": str(server.id),
                "server_name": server.name,
                "status": "unhealthy",
                "error": str(e),
                "message": "Health check failed",
            }

    def check_all_dependency_track_servers_health(self) -> List[Dict[str, Any]]:
        """
        Check the health of all active Dependency Track servers.

        Returns:
            List of health check results for all servers
        """
        servers = DependencyTrackServer.objects.filter(is_active=True)
        results = []

        for server in servers:
            result = self.check_dependency_track_server_health(server)
            results.append(result)

        logger.info(f"Completed health checks for {len(results)} DT servers")
        return results

    def _cache_dt_results(self, sbom, mapping: ComponentDependencyTrackMapping, results: Dict[str, Any]) -> None:
        """Store Dependency Track results in standardized format."""
        try:
            # Standardize the results using our unified processor
            standardized_results = StandardizedVulnerabilityData.normalize_scan_results(
                results, "dependency_track", "upload"
            )

            # Store results (always create new record for historical tracking)
            VulnerabilityScanResult.objects.create(
                sbom=sbom,
                component_mapping=mapping,
                provider="dependency_track",
                scan_trigger="upload",  # Default trigger
                vulnerability_count=standardized_results["vulnerability_count"],
                findings=standardized_results["findings"],
                scan_metadata=standardized_results["scan_metadata"],
                total_vulnerabilities=standardized_results["vulnerability_count"].get("total", 0),
                critical_vulnerabilities=standardized_results["vulnerability_count"].get("critical", 0),
                high_vulnerabilities=standardized_results["vulnerability_count"].get("high", 0),
                medium_vulnerabilities=standardized_results["vulnerability_count"].get("medium", 0),
                low_vulnerabilities=standardized_results["vulnerability_count"].get("low", 0),
            )

        except Exception as e:
            logger.warning(f"Failed to store DT results: {e}")

    def _process_dt_results(self, metrics: Dict[str, Any], vulnerabilities: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Process raw Dependency Track results into standardized format.

        Args:
            metrics: Project metrics from DT
            vulnerabilities: Vulnerability list from DT

        Returns:
            Processed results in standard format
        """
        # Count unique vulnerabilities by severity (not component-vulnerability pairs)
        severity_counts = {}
        unique_vulns = set()

        # First pass: count unique vulnerabilities by severity
        for finding in vulnerabilities:
            # DT returns findings with "component" and "vulnerability" structure
            vuln_data = finding.get("vulnerability", {})
            vuln_id = vuln_data.get("vulnId")
            severity = vuln_data.get("severity", "UNKNOWN").lower()

            if vuln_id not in unique_vulns:
                unique_vulns.add(vuln_id)
                if severity in ["critical", "high", "medium", "low", "info"]:
                    severity_counts[severity] = severity_counts.get(severity, 0) + 1

        vuln_counts = {
            "critical": severity_counts.get("critical", 0),
            "high": severity_counts.get("high", 0),
            "medium": severity_counts.get("medium", 0),
            "low": severity_counts.get("low", 0),
            "info": severity_counts.get("info", 0),
            "total": len(unique_vulns),
        }

        # Process vulnerabilities from DT Finding format
        processed_vulns = []
        for finding in vulnerabilities:
            # DT returns findings with "component" and "vulnerability" structure
            component_data = finding.get("component", {})
            vuln_data = finding.get("vulnerability", {})

            # Extract vulnerability info
            vuln_id = vuln_data.get("vulnId", "unknown")
            severity = vuln_data.get("severity", "UNKNOWN").lower()

            # Extract component info
            component_name = component_data.get("name", "Unknown Package")
            component_version = component_data.get("version", "Unknown Version")
            purl = component_data.get("purl", "")

            # Extract ecosystem from purl
            ecosystem = "Unknown"
            if purl.startswith("pkg:"):
                try:
                    ecosystem = purl.split(":")[1].split("/")[0]
                except (IndexError, AttributeError):
                    ecosystem = "Unknown"

            processed_vulns.append(
                {
                    "id": vuln_id,
                    "source": vuln_data.get("source", "Dependency Track"),
                    "severity": severity,
                    "title": vuln_data.get("title", vuln_data.get("description", ""))[:100] + "..."
                    if vuln_data.get("title") or vuln_data.get("description")
                    else "No description",
                    "summary": vuln_data.get("description", ""),
                    "description": vuln_data.get("description", ""),
                    "recommendation": vuln_data.get("recommendation", ""),
                    "references": vuln_data.get("references", [])
                    if isinstance(vuln_data.get("references", []), list)
                    else [],
                    "cvss_score": vuln_data.get("cvssV3BaseScore") or vuln_data.get("cvssV2BaseScore"),
                    "aliases": vuln_data.get("aliases", []),
                    "component": {
                        "name": component_name,
                        "version": component_version,
                        "ecosystem": ecosystem,
                        "purl": purl,
                    },
                }
            )

        return {
            "vulnerability_count": vuln_counts,
            "findings": processed_vulns,
            "metrics": metrics,
            "provider": "dependency_track",
            "scan_timestamp": timezone.now().isoformat(),
        }


# Helper functions for weekly vulnerability scanning


def get_weekly_scan_targets(days_back: int, team_key: str = None, max_releases: int = None):
    """Get list of releases to scan for weekly vulnerability scanning."""
    from django.utils import timezone

    from core.models import Release

    queryset = Release.objects.select_related(
        "product", "product__component", "product__component__team"
    ).prefetch_related("sboms")

    # Filter by team if specified
    if team_key:
        queryset = queryset.filter(product__component__team__key=team_key)

    # Filter by creation date
    if days_back:
        cutoff_date = timezone.now() - timedelta(days=days_back)
        queryset = queryset.filter(created_at__gte=cutoff_date)

    # Only get releases that have SBOMs
    queryset = queryset.filter(sboms__isnull=False).distinct()

    # Apply max limit if specified
    if max_releases:
        queryset = queryset[:max_releases]

    releases = list(queryset)
    logger.info(f"Found {len(releases)} releases with SBOMs for weekly scanning")
    return releases


def perform_weekly_scans(releases, force_rescan: bool = False):
    """Perform vulnerability scans on all releases for weekly scanning."""

    results = {
        "total_releases": len(releases),
        "total_sboms": 0,
        "successful_scans": 0,
        "failed_scans": 0,
        "skipped_scans": 0,
        "errors": [],
        "provider_stats": {},
    }

    service = VulnerabilityScanningService()

    for i, release in enumerate(releases, 1):
        logger.info(f"[WEEKLY_SCAN] [{i}/{len(releases)}] Scanning {release.product.name} v{release.name}...")

        # OSV vulnerability scanning is available for ALL teams
        # The VulnerabilityScanningService will handle provider selection

        # Scan all SBOMs for this release
        for sbom in release.sboms.all():
            results["total_sboms"] += 1

            try:
                # Check if recent scan exists (unless force rescan)
                if not force_rescan and _has_recent_weekly_scan(sbom):
                    logger.info(f"[WEEKLY_SCAN] Skipping {sbom.name} - recent scan exists")
                    results["skipped_scans"] += 1
                    continue

                # Perform scan
                scan_result = _scan_sbom_for_weekly(sbom, service)

                if scan_result and scan_result.get("status") != "error":
                    results["successful_scans"] += 1
                    provider = scan_result.get("provider", "unknown")
                    results["provider_stats"][provider] = results["provider_stats"].get(provider, 0) + 1
                    logger.info(f"[WEEKLY_SCAN] Successfully scanned {sbom.name} with {provider}")
                else:
                    results["failed_scans"] += 1
                    error_msg = scan_result.get("error", "Unknown error") if scan_result else "Scan returned None"
                    results["errors"].append(f"Failed to scan {sbom.name}: {error_msg}")
                    logger.error(f"[WEEKLY_SCAN] Failed to scan {sbom.name}: {error_msg}")

            except Exception as e:
                results["failed_scans"] += 1
                error_msg = f"Failed to scan {sbom.name}: {e}"
                results["errors"].append(error_msg)
                logger.exception(f"[WEEKLY_SCAN] {error_msg}")

    return results


def _has_recent_weekly_scan(sbom) -> bool:
    """Check if SBOM has been scanned recently (within 24 hours)."""
    from django.utils import timezone

    cutoff = timezone.now() - timedelta(hours=24)
    return VulnerabilityScanResult.objects.filter(sbom=sbom, created_at__gte=cutoff).exists()


def _scan_sbom_for_weekly(sbom, service):
    """Scan a single SBOM for vulnerabilities in weekly context."""
    try:
        # Use shared utility for SBOM data fetching
        from sboms.utils import SBOMDataError, get_sbom_data_bytes

        _, sbom_data = get_sbom_data_bytes(str(sbom.id))

        # Perform scan with weekly trigger
        scan_result = service.scan_sbom_for_vulnerabilities(sbom=sbom, sbom_data=sbom_data, scan_trigger="weekly")

        return scan_result

    except SBOMDataError as e:
        logger.error(f"Failed to get SBOM data for {sbom.id}: {e}")
        return None
    except Exception as e:
        logger.error(f"Failed to scan SBOM {sbom.id} in weekly context: {e}")
        return None


class DependencyTrackSetupService:
    """
    Service for managing Dependency Track component setup and backfill operations.

    This service handles the logic for finding components that need DT setup,
    processing their SBOMs, and ensuring proper DT mappings exist.
    """

    def __init__(self):
        """Initialize the DT setup service."""
        self.logger = logging.getLogger(f"{__name__}.DependencyTrackSetupService")
        self._vuln_service = None

    @property
    def vulnerability_service(self) -> VulnerabilityScanningService:
        """Lazy-load vulnerability scanning service."""
        if self._vuln_service is None:
            self._vuln_service = VulnerabilityScanningService()
        return self._vuln_service

    def find_components_needing_setup(self, team_key: str = None, max_components: int = None) -> List[Any]:
        """
        Find components that should use DT but have no mappings yet.

        Args:
            team_key: Only check components for a specific team
            max_components: Maximum number of components to return

        Returns:
            List of Component objects that need DT setup
        """
        from core.models import Component

        # Use select_for_update to prevent race conditions
        with transaction.atomic():
            # Start with all components that have SBOMs
            component_queryset = Component.objects.select_related("team").prefetch_related("sbom_set")

            # Filter by team if specified
            if team_key:
                component_queryset = component_queryset.filter(team__key=team_key)

            # Only components with SBOMs
            component_queryset = component_queryset.filter(sbom__isnull=False).distinct()

            # Apply limit if specified (get extra for filtering)
            if max_components:
                component_queryset = component_queryset[: max_components * 2]

            components = list(component_queryset)
            components_needing_setup = []

            for component in components:
                # Use select_for_update to prevent race conditions
                component = Component.objects.select_for_update().get(id=component.id)

                # Check if team should use DT
                if not self._team_should_use_dependency_track(component.team):
                    continue

                # Check if component already has a DT mapping
                if ComponentDependencyTrackMapping.objects.filter(component=component).exists():
                    continue

                # Check if component has relevant SBOMs
                relevant_sboms = self._get_relevant_sboms_for_component(component)
                if not relevant_sboms:
                    continue

                components_needing_setup.append(component)

                # Apply limit after filtering
                if max_components and len(components_needing_setup) >= max_components:
                    break

            self.logger.info(
                f"Found {len(components_needing_setup)} components needing DT setup "
                f"(filtered from {len(components)} total components)"
            )

            return components_needing_setup

    def process_components_for_setup(self, components: List[Any]) -> Dict[str, Any]:
        """
        Process components for DT setup with comprehensive error handling and monitoring.

        Args:
            components: List of Component objects to process

        Returns:
            Dictionary with detailed processing results and statistics
        """
        results = {
            "components_processed": len(components),
            "sboms_processed": 0,
            "successful_uploads": 0,
            "failed_uploads": 0,
            "skipped_uploads": 0,
            "errors": [],
            "successful_components": [],
            "failed_components": [],
            "processing_time_ms": 0,
            "performance_metrics": {
                "avg_sbom_download_time_ms": 0,
                "avg_upload_time_ms": 0,
                "total_data_processed_bytes": 0,
            },
        }

        import time

        start_time = time.time()
        download_times = []
        upload_times = []
        total_bytes = 0

        for i, component in enumerate(components, 1):
            self.logger.info(f"[{i}/{len(components)}] Processing component {component.name}...")

            try:
                component_result = self._process_single_component(component)

                # Aggregate results
                results["sboms_processed"] += component_result["sboms_processed"]
                results["successful_uploads"] += component_result["successful_uploads"]
                results["failed_uploads"] += component_result["failed_uploads"]
                results["skipped_uploads"] += component_result["skipped_uploads"]

                # Track performance metrics
                download_times.extend(component_result.get("download_times", []))
                upload_times.extend(component_result.get("upload_times", []))
                total_bytes += component_result.get("bytes_processed", 0)

                if component_result["success"]:
                    results["successful_components"].append(component.name)
                else:
                    results["failed_components"].append(
                        {"component": component.name, "errors": component_result["errors"]}
                    )
                    results["errors"].extend(component_result["errors"])

            except Exception as comp_error:
                error_msg = f"Component {component.name}: {str(comp_error)}"
                results["errors"].append(error_msg)
                results["failed_components"].append({"component": component.name, "errors": [str(comp_error)]})
                self.logger.exception(f"Error processing component {component.name}: {comp_error}")

        # Calculate performance metrics
        results["processing_time_ms"] = int((time.time() - start_time) * 1000)
        if download_times:
            results["performance_metrics"]["avg_sbom_download_time_ms"] = int(sum(download_times) / len(download_times))
        if upload_times:
            results["performance_metrics"]["avg_upload_time_ms"] = int(sum(upload_times) / len(upload_times))
        results["performance_metrics"]["total_data_processed_bytes"] = total_bytes

        return results

    def _process_single_component(self, component) -> Dict[str, Any]:
        """Process a single component for DT setup."""
        component_result = {
            "success": False,
            "sboms_processed": 0,
            "successful_uploads": 0,
            "failed_uploads": 0,
            "skipped_uploads": 0,
            "errors": [],
            "download_times": [],
            "upload_times": [],
            "bytes_processed": 0,
        }

        # Get relevant SBOMs for this component
        relevant_sboms = self._get_relevant_sboms_for_component(component)

        if not relevant_sboms:
            self.logger.warning(f"No relevant SBOMs found for component {component.name}")
            component_result["skipped_uploads"] += 1
            return component_result

        import time

        # Process each relevant SBOM
        for sbom, source_type in relevant_sboms:
            try:
                self.logger.info(f"Processing SBOM {sbom.name} ({source_type}) for component {component.name}")

                # Download SBOM data with timing using shared utility
                download_start = time.time()
                try:
                    from sboms.utils import SBOMDataError, get_sbom_data_bytes

                    _, sbom_data = get_sbom_data_bytes(str(sbom.id))
                except SBOMDataError as e:
                    self.logger.warning(f"Could not get SBOM data for {sbom.id}: {e}")
                    continue

                download_time = (time.time() - download_start) * 1000
                component_result["download_times"].append(download_time)
                component_result["bytes_processed"] += len(sbom_data)

                # Perform upload/scan with timing
                upload_start = time.time()
                scan_result = self.vulnerability_service.scan_sbom_for_vulnerabilities(
                    sbom=sbom, sbom_data=sbom_data, scan_trigger="recurring_setup"
                )
                upload_time = (time.time() - upload_start) * 1000
                component_result["upload_times"].append(upload_time)

                if scan_result and scan_result.get("provider") == "dependency_track":
                    component_result["successful_uploads"] += 1
                    component_result["success"] = True
                    self.logger.info(f"Successfully uploaded {sbom.name} to DT")
                else:
                    component_result["failed_uploads"] += 1
                    error_msg = scan_result.get("error", "Unknown error") if scan_result else "No result"
                    component_result["errors"].append(f"SBOM {sbom.name}: {error_msg}")
                    self.logger.error(f"Failed to upload {sbom.name}: {error_msg}")

                component_result["sboms_processed"] += 1

            except Exception as sbom_error:
                component_result["failed_uploads"] += 1
                component_result["sboms_processed"] += 1
                error_msg = f"SBOM {sbom.name}: {str(sbom_error)}"
                component_result["errors"].append(error_msg)
                self.logger.exception(f"Error processing SBOM {sbom.name}: {sbom_error}")

        return component_result

    def _team_should_use_dependency_track(self, team) -> bool:
        """Check if a team should use Dependency Track for vulnerability scanning."""
        try:
            settings = TeamVulnerabilitySettings.objects.get(team=team)
            return settings.vulnerability_provider == "dependency_track"
        except TeamVulnerabilitySettings.DoesNotExist:
            # Check if team is enterprise/business tier (they can use DT)
            # For now, default to False - teams must explicitly configure DT
            return False

    def _get_relevant_sboms_for_component(self, component):
        """Get relevant SBOMs for a component (latest + tagged releases)."""
        sboms_to_process = []

        # 1. Latest SBOM
        latest_sbom = component.latest_sbom
        if latest_sbom:
            sboms_to_process.append((latest_sbom, "component_latest"))

        # 2. SBOMs from tagged releases (not just recent ones for backfill)
        from core.models import Release

        tagged_releases = Release.objects.filter(
            product__team=component.team, artifacts__sbom__component=component
        ).distinct()

        for release in tagged_releases:
            for artifact in release.artifacts.filter(sbom__component=component):
                sbom = artifact.sbom
                # Don't duplicate the latest SBOM
                if latest_sbom and sbom.id == latest_sbom.id:
                    continue
                sboms_to_process.append((sbom, f"release_{release.name}"))

        return sboms_to_process
